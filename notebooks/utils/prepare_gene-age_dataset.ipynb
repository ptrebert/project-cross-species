{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys as sys\n",
    "import os as os\n",
    "import pickle as pck\n",
    "import collections as col\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fhgfs_base = '/TL/deep/fhgfs/projects/pebert/thesis'\n",
    "stat_folder = os.path.join(fhgfs_base, 'projects/cross_species/processing/norm/task_summarize')\n",
    "stat_file = os.path.join(stat_folder, 'agg_expstat_est.h5')\n",
    "\n",
    "cache_dir = '/home/pebert/.jupyter/cache'\n",
    "\n",
    "feature_dir = os.path.join(fhgfs_base, 'projects/cross_species/processing/norm/task_testdata_exp/test_datasets')\n",
    "\n",
    "annotated_species = ['human', 'mouse', 'cow', 'opossum', 'chicken',\n",
    "                     'rhesus', 'rat', 'dog']\n",
    "\n",
    "assm_map = {'human': 'hg19', 'mouse': 'mm9', 'opossum': 'monDom5', 'rhesus': 'rheMac2',\n",
    "           'rat': 'rn5', 'dog': 'canFam3', 'cow': 'bosTau7', 'chicken': 'galGal3'}\n",
    "\n",
    "column_map = {'Cellular_organisms': 'ftage_abs_cellorg', 'Euk_Archaea': 'ftage_abs_eukarch',\n",
    "              'Euk+Bac': 'ftage_abs_eukbac', 'Eukaryota': 'ftage_abs_euk',\n",
    "              'Opisthokonta': 'ftage_abs_opist', 'Eumetazoa': 'ftage_abs_eumeta',\n",
    "              'Vertebrata': 'ftage_abs_vert',  'Mammalia': 'ftage_abs_mamm',\n",
    "              'entropy': 'ftconf_abs_entropy', 'Bimodality': 'ftconf_abs_bimodality',\n",
    "              'NodeError': 'ftconf_abs_nodeerror', 'HGT_flag': 'ftconf_bin_hgt'}\n",
    "\n",
    "out_dir = '/TL/deep/fhgfs/projects/pebert/thesis/refdata/geneage/norm'\n",
    "run_norm = True\n",
    "run_collect = True\n",
    "run_finalize = True\n",
    "\n",
    "def map_identifiers():\n",
    "    ga_annot = '/TL/deep/fhgfs/projects/pebert/thesis/refdata/geneage/raw'\n",
    "    up_map = '/TL/deep/fhgfs/projects/pebert/thesis/refdata/geneage/map_uniprot'\n",
    "    ens_map = '/TL/deep/fhgfs/projects/pebert/thesis/refdata/geneage/map_ensembl'\n",
    "    \n",
    "    for fn in os.listdir(ga_annot):\n",
    "        species = fn.split('.')[0].split('_')[1]\n",
    "        ent_col = '{}_entity'.format(species)\n",
    "        name_col = '{}_name'.format(species)\n",
    "        \n",
    "        fp = os.path.join(ga_annot, fn)\n",
    "        df = normalize_annotation(fp, species)\n",
    "\n",
    "        up_fp = os.path.join(up_map, '{}_uniprot_ensgene.txt'.format(species))\n",
    "        up_df = pd.read_csv(up_fp, sep='\\t')\n",
    "        up_df.columns = [ent_col, name_col]\n",
    "        df = df.merge(up_df, on=ent_col, how='outer')\n",
    "        \n",
    "        ens_fp = os.path.join(ens_map, '{}_ensprot_ensgene.txt'.format(species))\n",
    "        ens_df = pd.read_csv(ens_fp, sep='\\t')\n",
    "        ens_df.drop(['Ensembl Transcript ID'], axis=1, inplace=True)\n",
    "        ens_df = ens_df.loc[ens_df['Ensembl Protein ID'].isin(df[ent_col]), :].copy()\n",
    "        ens_df.columns = [name_col, ent_col]\n",
    "        df = df.merge(ens_df, on=[ent_col, name_col], how='outer')\n",
    "        \n",
    "        df.dropna(axis=0, how='any', inplace=True)\n",
    "        df.drop_duplicates(subset=['{}_name'.format(species)], inplace=True)       \n",
    "        if pd.isnull(df).any(axis=0).any():\n",
    "            null_col = np.array(pd.isnull(df).any(axis=0), dtype=np.bool)\n",
    "            null_row = np.array(pd.isnull(df).any(axis=1), dtype=np.bool)\n",
    "            null_sub = df.loc[null_row, null_col]\n",
    "            print(null_sub.shape)\n",
    "            print(df.columns[null_col])\n",
    "            print(null_sub.head())\n",
    "            print(null_sub.tail())\n",
    "            raise ValueError('NULL after dropping')\n",
    "        \n",
    "        if species == 'chicken':\n",
    "            df['ftage_abs_mamm'] = 0\n",
    "        \n",
    "        outname = '{}_agefeat.h5'.format(species)\n",
    "        outpath = os.path.join(out_dir, outname)\n",
    "        with pd.HDFStore(outpath, 'w', complevel=9) as hdf:\n",
    "            hdf.put('feat', df, format='table')\n",
    "    return True\n",
    "  \n",
    "\n",
    "def normalize_annotation(fp, species):\n",
    "    df = pd.read_csv(fp, sep=',', na_values='None')\n",
    "    # impute missing values\n",
    "    bimod_mean = df['Bimodality'].mean()\n",
    "    nderr_mean = df['NodeError'].mean()\n",
    "    \n",
    "    df.loc[pd.isnull(df['Bimodality']), 'Bimodality'] = bimod_mean\n",
    "    df.loc[pd.isnull(df['NodeError']), 'NodeError'] = nderr_mean\n",
    "    \n",
    "    new_columns = []\n",
    "    for c in df.columns:\n",
    "        new_c = column_map.get(c, c)\n",
    "        new_columns.append(new_c)\n",
    "    df.columns = new_columns\n",
    "    df.index = df['{}_entity'.format(species)]\n",
    "    to_drop = [c for c in df.columns if 'DB' in c]\n",
    "    df.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "    if pd.isnull(df).any(axis=0).any():\n",
    "        null_col = np.array(pd.isnull(df).any(axis=0), dtype=np.bool)\n",
    "        null_row = np.array(pd.isnull(df).any(axis=1), dtype=np.bool)\n",
    "        null_sub = df.loc[null_row, null_col]\n",
    "        print(null_sub.shape)\n",
    "        print(df.columns[null_col])\n",
    "        print(null_sub.head())\n",
    "        print(null_sub.tail())\n",
    "            \n",
    "        raise ValueError('NULL after reading')\n",
    "    \n",
    "    # \"normalize\" df entries\n",
    "    df.replace({'modeAge': column_map}, inplace=True)\n",
    "    df['ftconf_bin_hgt'] = df['ftconf_bin_hgt'].astype(np.int8, copy=True)\n",
    "    ga_feat_names = []\n",
    "    for v in column_map.values():\n",
    "        if v.startswith('ftage'):\n",
    "            w = v.replace('_abs_', '_bin_')\n",
    "            ga_feat_names.append(w)\n",
    "    ga_feat_names = sorted(ga_feat_names)\n",
    "    # add gene age feature\n",
    "    ga_feat = pd.DataFrame(np.zeros((df.shape[0], len(ga_feat_names)), dtype=np.int8),\n",
    "                           index=df.index, columns=ga_feat_names)\n",
    "    for age_class in df['modeAge'].unique():\n",
    "        entities = df.loc[df['modeAge'] == age_class, :].index\n",
    "        age_cat = age_class.replace('_abs_', '_bin_')\n",
    "        ga_feat.loc[entities, age_cat] = 1\n",
    "    df = df.join(ga_feat, how='inner')\n",
    "    df.drop(['modeAge'], axis=1, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    if pd.isnull(df).any(axis=0).any():\n",
    "        null_col = np.array(pd.isnull(df).any(axis=0), dtype=np.bool)\n",
    "        null_row = np.array(pd.isnull(df).any(axis=1), dtype=np.bool)\n",
    "        null_sub = df.loc[null_row, null_col]\n",
    "        print(null_sub.shape)\n",
    "        print(df.columns[null_col])\n",
    "        print(null_sub.head())\n",
    "        print(null_sub.tail())\n",
    "        raise ValueError('NULL after normalizing')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def collect_model_stat_perf(fpath, species):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    done = set()\n",
    "    cache_keys = os.path.join(cache_dir, 'geneage_keys.pck')\n",
    "    count_collect = dict()\n",
    "    data_collect = dict()\n",
    "    with pd.HDFStore(fpath, 'r') as hdf:\n",
    "        if os.path.isfile(cache_keys):\n",
    "            all_keys = pck.load(open(cache_keys, 'rb'))\n",
    "        else:\n",
    "            all_keys = list(hdf.keys())\n",
    "            all_keys = list(filter(lambda x: x.startswith('/pos/can') and x.endswith('/data'), all_keys))\n",
    "            all_keys = list(filter(lambda x: all([c not in x for c in ['GM12878', 'CH12', 'K562', 'MEL', 'brain']]), all_keys))\n",
    "            with open(cache_keys, 'wb') as dump:\n",
    "                pck.dump(all_keys, dump)\n",
    "        for k in all_keys:\n",
    "            data = hdf[k]\n",
    "            path_comp = k.split('/')\n",
    "            ref_spec, qry_spec = path_comp[3], path_comp[4]\n",
    "            if not (ref_spec in species and qry_spec in species):\n",
    "                continue\n",
    "            ref_data, qry_data = path_comp[5], path_comp[6]\n",
    "            if (ref_data, qry_data) in done:\n",
    "                continue\n",
    "            else:\n",
    "                done.add((ref_data, qry_data))\n",
    "            if (ref_spec, qry_spec) not in data_collect:\n",
    "                sub = data.loc[:, ['pair_ortho', 'group_ortho']].copy()\n",
    "                sub.columns = ['ftorth_pair', 'ftorth_group']\n",
    "                sub['true_pred'] = 0\n",
    "                sub['false_pred'] = 0\n",
    "                data_collect[(ref_spec, qry_spec)] = sub\n",
    "            if (ref_spec, qry_spec) not in count_collect:\n",
    "                count_collect[(ref_spec, qry_spec)] = {'true_pred': col.Counter(),\n",
    "                                                       'false_pred': col.Counter()}\n",
    "            gene_names = data.index\n",
    "            \n",
    "            true_pos = np.array(data['tp'].values, dtype=np.bool)\n",
    "            true_neg = np.array(data['tn'].values, dtype=np.bool)\n",
    "            true_select = np.logical_or(true_pos, true_neg)\n",
    "            \n",
    "            select_names = gene_names[true_select].tolist()\n",
    "            count_collect[(ref_spec, qry_spec)]['true_pred'].update(select_names)\n",
    "            \n",
    "            select_names = gene_names[~true_select].tolist()\n",
    "            count_collect[(ref_spec, qry_spec)]['false_pred'].update(select_names)\n",
    "    \n",
    "    final_collect = dict()\n",
    "    for ref, qry in data_collect.keys():\n",
    "        base_data = data_collect[(ref, qry)]\n",
    "        true_pred = pd.DataFrame.from_dict(count_collect[(ref, qry)]['true_pred'],\n",
    "                                           orient='index', dtype=np.int32)\n",
    "        true_pred.columns = ['true_pred']        \n",
    "        base_data.loc[true_pred.index, 'true_pred'] = true_pred\n",
    "                \n",
    "        false_pred = pd.DataFrame.from_dict(count_collect[(ref, qry)]['false_pred'],\n",
    "                                            orient='index', dtype=np.int32)\n",
    "        false_pred.columns = ['false_pred']\n",
    "        base_data.loc[false_pred.index, 'false_pred'] = false_pred\n",
    "        \n",
    "        base_data['total_pred'] = base_data['true_pred'] + base_data['false_pred']\n",
    "        base_data['target'] = base_data['true_pred'] / base_data['total_pred']\n",
    "        \n",
    "        base_data = add_conservation_feature(base_data, ref, qry)\n",
    "        \n",
    "        assert not (pd.isnull(base_data).any(axis=0).any()), 'Base data has NULL'\n",
    "                \n",
    "        cache_file = os.path.join(out_dir, '{}_agefeat.h5'.format(qry))\n",
    "        with pd.HDFStore(cache_file, 'a') as hdf:\n",
    "            hdf.put('model/{}'.format(ref), base_data, format='table')\n",
    "        final_collect[(ref, qry)] = base_data\n",
    "        \n",
    "    done_queries = set()\n",
    "    for ref, qry in final_collect.keys():\n",
    "        if qry in ['human', 'mouse']:\n",
    "            continue\n",
    "        if qry in done_queries:\n",
    "            continue\n",
    "        if ref == 'human':\n",
    "            ref2 = 'mouse'\n",
    "        else:\n",
    "            ref2 = 'human'\n",
    "        final = final_collect[(ref, qry)]\n",
    "        try:\n",
    "            data2 = final_collect[(ref2, qry)]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        done_queries.add(qry)\n",
    "        final['true_pred'] += data2['true_pred']\n",
    "        final['false_pred'] += data2['false_pred']\n",
    "        final['total_pred'] = final['true_pred'] + final['false_pred']\n",
    "        final['target'] = final['true_pred'] / final['total_pred']\n",
    "        \n",
    "        final['ftorth_pair'] += data2['ftorth_pair']\n",
    "        final['ftcons_pct_reg5p'] += data2['ftcons_pct_reg5p']\n",
    "        final['ftcons_pct_reg5p'] /= 2\n",
    "        final['ftcons_pct_body'] += data2['ftcons_pct_body']\n",
    "        final['ftcons_pct_body'] /= 2\n",
    "        \n",
    "        assert not pd.isnull(final).any(axis=0).any(), 'Final has NULL'\n",
    "        \n",
    "        cache_file = os.path.join(out_dir, '{}_agefeat.h5'.format(qry))\n",
    "        with pd.HDFStore(cache_file, 'a') as hdf:\n",
    "            hdf.put('model/joint', final, format='table')\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def add_conservation_feature(dataframe, ref, qry):\n",
    "    ref_assm = assm_map[ref]\n",
    "    qry_assm = assm_map[qry]\n",
    "    folder = os.path.join(feature_dir, '{}_from_{}'.format(qry_assm, ref_assm))\n",
    "    all_files = os.listdir(folder)\n",
    "    all_files = list(filter(lambda x: x.endswith('.feat.h5'), all_files))\n",
    "    for fn in all_files:\n",
    "        fp = os.path.join(folder, fn)\n",
    "        data = []\n",
    "        with pd.HDFStore(fp, 'r') as hdf:\n",
    "            for k in hdf.keys():\n",
    "                if k == '/metadata':\n",
    "                    continue\n",
    "                data.append(hdf[k])\n",
    "        data = pd.concat(data, axis=0, ignore_index=False)\n",
    "        data.index = data['name']\n",
    "        keep_cols = ['ftmsig_H3K4me3_pct_cons_reg5p', 'ftmsig_H3K36me3_pct_cons_body']\n",
    "        data = data.loc[:, keep_cols].copy()\n",
    "        data.columns = ['ftcons_pct_reg5p', 'ftcons_pct_body']\n",
    "        dataframe = pd.concat([dataframe, data], ignore_index=False, axis=1)\n",
    "        break\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def finalize_featuresets():\n",
    "    featfiles = os.listdir(out_dir)\n",
    "    for ff in featfiles:\n",
    "        fp = os.path.join(out_dir, ff)\n",
    "        with pd.HDFStore(fp, 'a') as hdf:\n",
    "            age_feat = hdf['/feat']\n",
    "            assert not (pd.isnull(age_feat).any(axis=0).any()), 'NULL before finalize'\n",
    "            name_col = [c for c in age_feat.columns if c.endswith('name')]\n",
    "            name_col = name_col[0]\n",
    "            age_feat.index = age_feat[name_col]\n",
    "            rem_cols = [c for c in age_feat.columns if c.endswith('entity')]\n",
    "            rem_cols.append(name_col)\n",
    "            age_feat.drop(rem_cols, axis=1, inplace=True)\n",
    "            model_keys = [k for k in hdf.keys() if k.startswith('/model')]\n",
    "            for k in model_keys:\n",
    "                model_type = k.split('/')[2]\n",
    "                model_data = hdf[k]\n",
    "                assert not (pd.isnull(model_data).any(axis=0).any()), 'Model data NULL: {}'.format(k)\n",
    "                sub_feat = age_feat.loc[age_feat.index.isin(model_data.index), :].copy()\n",
    "                sub_model = model_data.loc[model_data.index.isin(sub_feat.index), :].copy()\n",
    "                \n",
    "                final = pd.concat([sub_model, sub_feat], axis=1, ignore_index=False)\n",
    "                final['name'] = final.index\n",
    "                final.reset_index(drop=True, inplace=True)\n",
    "                assert not (pd.isnull(final).any(axis=0).any()), 'Final data NULL: {}'.format(k)\n",
    "                out_group = os.path.join(k, 'final')\n",
    "                hdf.put(out_group, final, format='table')\n",
    "    return  \n",
    "\n",
    "if run_norm:           \n",
    "    map_identifiers()\n",
    "    \n",
    "if run_collect:\n",
    "    collect_model_stat_perf(stat_file, annotated_species)\n",
    "\n",
    "if run_finalize:\n",
    "    finalize_featuresets()\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
