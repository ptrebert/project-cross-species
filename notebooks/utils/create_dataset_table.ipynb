{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/TL/epigenetics2/work/pebert/conda/envs/py3/lib/python3.5/site-packages/ipykernel_launcher.py:131: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os as os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "annotation_root = '/home/pebert/work/code/mpggit/crossspecies/annotation'\n",
    "ar = annotation_root\n",
    "\n",
    "data_root = '/TL/deep/fhgfs/projects/pebert/thesis/projects/cross_species'\n",
    "\n",
    "base_out = '/TL/deep-external01/nobackup/pebert/cloudshare/mpiinf/phd/chapter_projects/crossspecies'\n",
    "supp_out = os.path.join(base_out, 'supplement', 'supp_tables')\n",
    "\n",
    "table_out = os.path.join(supp_out, 'Additional-file-2_Data-sources.tsv')\n",
    "\n",
    "dataset_file = os.path.join(ar, 'exec', 'datasets.tsv')\n",
    "blueprint_file = os.path.join(ar, 'datasrc', 'blueprint', 'blueprint_metadata_ro.tsv')\n",
    "deep_file = os.path.join(ar, 'datasrc', 'deep', '20170516_deep.tsv')\n",
    "encode_file = os.path.join(ar, 'datasrc', 'encode', 'encode_metadata_ro.tsv')\n",
    "sra_file = os.path.join(ar, 'datasrc', 'sra', '20170818_SRA_expression_fastq.tsv')\n",
    "\n",
    "def read_project_datasets(fpath):\n",
    "    df = pd.read_csv(fpath, sep='\\t')\n",
    "    df = df.loc[df['comment'] != 'ignore', :].copy()\n",
    "    df = df.loc[df['comment'] != 'dnase', :].copy()\n",
    "    df.drop(['multid', 'layout', 'lifestage', 'experiment'], axis=1, inplace=True)\n",
    "    df.columns = ['short_id'] + df.columns[1:].tolist()\n",
    "    df = df.astype(str)\n",
    "    annot = dict()\n",
    "    for row in df.itertuples():\n",
    "        sid = row.short_id\n",
    "        com = row.comment\n",
    "        if com != 'complete':\n",
    "            if com == 'histone':\n",
    "                com = 'complete'\n",
    "        if row.lab == 'AFSCAM':\n",
    "            lut_key = row.assembly, row.type, row.project, row.biosample, 'WTSI'\n",
    "            annot[lut_key] = sid, com\n",
    "            lut_key = row.assembly, row.type, row.project, row.biosample, 'NCMLS'\n",
    "            annot[lut_key] = sid, com\n",
    "        else:\n",
    "            lut_key = row.assembly, row.type, row.project, row.biosample, row.lab\n",
    "            annot[lut_key] = sid, com\n",
    "    return annot\n",
    "\n",
    "def read_blueprint_metadata(fpath):\n",
    "    \n",
    "    ena_project_md = os.path.join(ar, 'datasrc/sra/20170512_ENA_PRJEB14054_ERP015660.txt')\n",
    "    ena_project = pd.read_csv(ena_project_md, sep='\\t', header=0)\n",
    "    ena_project = ena_project[['run_accession', 'fastq_ftp']]\n",
    "        \n",
    "    df = pd.read_csv(fpath, sep='\\t')\n",
    "    df['filename'] = df['fastq_path'].str.extract('.+/(?P<FNAME>[\\w\\.]+)$', expand=True)\n",
    "    df.drop(['AssemblyName', 'ReadHash', 'InsertDev', 'LibrarySelection', 'RunHash', 'fastq_path',\n",
    "             'LoadDate', 'spots_with_mates', 'bases', 'Model', 'LibraryStrategy',\n",
    "             'Platform', 'SampleName', 'ScientificName', 'InsertSize', 'Tumor', 'SampleType',\n",
    "             'LibrarySource', 'Consent', 'avgLength', 'ProjectID', 'size_MB', 'spots', 'Sex',\n",
    "             'Submission', 'ReleaseDate', 'Subject_ID', 'TaxID', 'LibraryLayout'],\n",
    "            axis=1, inplace=True)\n",
    "    df = df.loc[df['short_biosample'] == 'ncd4', :].copy()\n",
    "    select_libs = df['Experiment_target'].isin(['H3K4me3', 'H3K27ac', 'H3K36me3'])\n",
    "    df = df.loc[select_libs, :].copy()\n",
    "    df['assembly'] = 'mm9'\n",
    "    df['biosample'] = 'ncd4'\n",
    "    df['project'] = 'BLUEPRINT'\n",
    "    df['type'] = 'epigenome'\n",
    "    df['lab'] = 'unknown'\n",
    "    df.loc[df['CenterName'].str.startswith('Nijmegen'), 'lab'] = 'NCMLS'\n",
    "    df.loc[df['CenterName'].str.startswith('THE'), 'lab'] = 'WTSI'\n",
    "    df.drop(['short_biosample', 'CenterName'], axis=1, inplace=True)\n",
    "    new_cols = []\n",
    "    for c in df.columns:\n",
    "        if c == 'download_path':\n",
    "            new_cols.append('url')\n",
    "        elif c == 'Biological_replicate':\n",
    "            new_cols.append('rep')\n",
    "        else:\n",
    "            new_cols.append(c)\n",
    "    df.columns = new_cols\n",
    "    df['Output_type'] = 'reads'\n",
    "    df['Biosample_type'] = 'cell'\n",
    "    df = df.astype(str)\n",
    "    # replace download URL with interpretable EBI/ENA version\n",
    "    for row in df.itertuples():\n",
    "        if row.filename.endswith('_1.fastq.gz'):\n",
    "            f1, _ = ena_project.loc[ena_project['run_accession'] == row.Run, 'fastq_ftp'].values[0].split(';')\n",
    "            assert f1.endswith('_1.fastq.gz'), 'Filename mismatch: {} / {}'.format(row.filename, f1)\n",
    "            df.loc[row.Index, 'url'] = f1\n",
    "        elif row.filename.endswith('_2.fastq.gz'):\n",
    "            _, f2 = ena_project.loc[ena_project['run_accession'] == row.Run, 'fastq_ftp'].values[0].split(';')\n",
    "            assert f2.endswith('_2.fastq.gz'), 'Filename mismatch: {} / {}'.format(row.filename, f1)\n",
    "            df.loc[row.Index, 'url'] = f2\n",
    "        else:\n",
    "            f = ena_project.loc[ena_project['run_accession'] == row.Run, 'fastq_ftp'].values[0]\n",
    "            df.loc[row.Index, 'url'] = f\n",
    "    return df\n",
    "\n",
    "def read_deep_metadata(fpath):\n",
    "    ihec_url = 'http://epigenomesportal.ca/tracks/DEEP/hg19'\n",
    "    pub_url = {'41_Hf01_LiHe_Ct_H3K27ac_F_1.CHPv3.20150501.hs37.bamcov.bw':\n",
    "               '63039.DEEP.41_Hf01_LiHe_Ct.H3K27ac.signal_unstranded.bigWig',\n",
    "               '41_Hf02_LiHe_Ct_H3K27ac_F_1.CHPv3.20150501.hs37.bamcov.bw':\n",
    "               '63064.DEEP.41_Hf02_LiHe_Ct.H3K27ac.signal_unstranded.bigWig',\n",
    "               '41_Hf03_LiHe_Ct_H3K27ac_F_1.CHPv3.20150501.hs37.bamcov.bw':\n",
    "               '63085.DEEP.41_Hf03_LiHe_Ct.H3K27ac.signal_unstranded.bigWig',\n",
    "               '41_Hf01_LiHe_Ct_H3K36me3_F_1.CHPv3.20150501.hs37.bamcov.bw':\n",
    "               '63043.DEEP.41_Hf01_LiHe_Ct.H3K36me3.signal_unstranded.bigWig',\n",
    "               '41_Hf02_LiHe_Ct_H3K36me3_F_1.CHPv3.20150501.hs37.bamcov.bw':\n",
    "               '63068.DEEP.41_Hf02_LiHe_Ct.H3K36me3.signal_unstranded.bigWig',\n",
    "               '41_Hf03_LiHe_Ct_H3K36me3_F_1.CHPv3.20150501.hs37.bamcov.bw':\n",
    "               '63089.DEEP.41_Hf03_LiHe_Ct.H3K36me3.signal_unstranded.bigWig',\n",
    "               '41_Hf01_LiHe_Ct_H3K4me3_F_1.CHPv3.20150501.hs37.bamcov.bw':\n",
    "               '63047.DEEP.41_Hf01_LiHe_Ct.H3K4me3.signal_unstranded.bigWig',\n",
    "               '41_Hf02_LiHe_Ct_H3K4me3_F_1.CHPv3.20150501.hs37.bamcov.bw':\n",
    "               '63072.DEEP.41_Hf02_LiHe_Ct.H3K4me3.signal_unstranded.bigWig',\n",
    "               '41_Hf03_LiHe_Ct_H3K4me3_F_1.CHPv3.20150501.hs37.bamcov.bw':\n",
    "               '63093.DEEP.41_Hf03_LiHe_Ct.H3K4me3.signal_unstranded.bigWig'}\n",
    "    \n",
    "               # CD4+ data have not yet been released as hg19 trackhub\n",
    "               \n",
    "#                '51_Hf03_BlTN_Ct_H3K27ac_B_1.CHPv4.20150928.hs37.raw.bamcov.bw':,\n",
    "#                '51_Hf04_BlTN_Ct_H3K27ac_B_1.CHPv4.20150708.hs37.raw.bamcov.bw':,\n",
    "#                '51_Hf03_BlTN_Ct_H3K36me3_B_1.CHPv4.20150928.hs37.raw.bamcov.bw':,\n",
    "#                '51_Hf04_BlTN_Ct_H3K36me3_B_1.CHPv4.20150708.hs37.raw.bamcov.bw':,\n",
    "#                '51_Hf03_BlTN_Ct_H3K4me3_B_1.CHPv4.20150928.hs37.raw.bamcov.bw':,\n",
    "#                '51_Hf04_BlTN_Ct_H3K4me3_B_1.CHPv4.20150708.hs37.raw.bamcov.bw':\n",
    "\n",
    "    df = pd.read_csv(fpath, sep='\\t')\n",
    "    df.drop(['lifestage'], axis=1, inplace=True)\n",
    "    select_libs = df['filename'].str.contains('(H3K36me3|H3K4me3|H3K27ac|mRNA)', case=True)\n",
    "    df = df.loc[select_libs, :].copy()\n",
    "    df['Experiment_target'] = df['filename'].str.extract('(H3K36me3|H3K4me3|H3K27ac|mRNA)', expand=False)\n",
    "    df['url'] = df['url'].str.replace('local', 'local file - see www.epigenomesportal.ca/ihec for public version')\n",
    "    df['project'] = 'DEEP'\n",
    "    df['type'] = 'unknown'\n",
    "    df.loc[df['filename'].str.endswith('.fastq.gz'), 'type'] = 'transcriptome'\n",
    "    df.loc[df['filename'].str.endswith('.bw'), 'type'] = 'epigenome'\n",
    "    df.loc[df['type'] == 'transcriptome', 'url'] = 'https://aspera.dkfz.de:' + df.loc[df['type'] == 'transcriptome', 'url']\n",
    "    df['Output_type'] = 'unknown'\n",
    "    df.loc[df['type'] == 'epigenome', 'Output_type'] = 'signal'\n",
    "    df.loc[df['type'] == 'transcriptome', 'Output_type'] = 'reads'\n",
    "    df['Biosample_type'] = 'cell'\n",
    "    for row in df.itertuples():\n",
    "        if row.type == 'epigenome':\n",
    "            try:\n",
    "                thb = pub_url[row.filename]\n",
    "                df.loc[row.Index, 'url'] = os.path.join(ihec_url, thb)\n",
    "            except KeyError:\n",
    "                df.loc[row.Index, 'url'] = 'no-IHEC-trackhub-available-request-raw-data-access'\n",
    "    df = df.astype(str)\n",
    "    return df\n",
    "\n",
    "def read_encode_metadata(fpath):\n",
    "    df = pd.read_csv(fpath, sep='\\t')\n",
    "    deselect_samples = np.array(df['Biosample term name'].isin(['CH12', 'MEL', 'GM12878', 'K562']), dtype=np.bool)\n",
    "    deselect_libs = np.array(df['Assay'] == 'DNase-seq', dtype=np.bool)\n",
    "    deselect = np.logical_or(deselect_samples, deselect_libs)\n",
    "    df = df.loc[~deselect, :].copy()\n",
    "    \n",
    "    select_libs = df['Experiment target'].isin(['H3K4me3', 'H3K36me3', 'H3K27ac'])\n",
    "    select_assay = df['Assay'].isin(['RNA-seq'])\n",
    "    select_both = np.logical_or(select_libs, select_assay)\n",
    "    df = df.loc[select_both, :].copy()\n",
    "    df['type'] = 'unknown'\n",
    "    df.loc[df['Assay'] == 'ChIP-seq', 'type'] = 'epigenome'\n",
    "    df.loc[df['Assay'] == 'RNA-seq', 'type'] = 'transcriptome'\n",
    "    \n",
    "    df.drop(['Technical replicate', 'Read length', 'Run type', 'Paired end',\n",
    "             'Paired with', 'Derived from', 'Platform', 'Antibody accession',\n",
    "             'Biological replicate(s)', 'Biosample Age', 'Library size range',\n",
    "             'Library depleted in', 'Library made from', 'Assay', 'Assembly',\n",
    "             'File format', 'Biosample life stage'],\n",
    "            axis=1, inplace=True)\n",
    "    \n",
    "    df['project'] = 'ENCODE'\n",
    "    df['assembly'] = 'unknown'\n",
    "    df.loc[df['Biosample organism'] == 'hsa', 'assembly'] = 'hg19'\n",
    "    df.loc[df['Biosample organism'] == 'mmu', 'assembly'] = 'mm9'\n",
    "    new_cols = []\n",
    "    for c in df.columns:\n",
    "        if c == 'Biosample term name':\n",
    "            new_cols.append('biosample')\n",
    "        elif c == 'Lab':\n",
    "            new_cols.append('lab')\n",
    "        elif c == 'Biosample organism':\n",
    "            new_cols.append('species')\n",
    "        elif c == 'File download URL':\n",
    "            new_cols.append('url')\n",
    "        else:\n",
    "            new_cols.append(c.replace(' ', '_'))\n",
    "    df.columns = new_cols\n",
    "    filenames = df['url'].str.extract('/(ENC[A-Z0-9]+\\.(bigWig|fastq\\.gz))', expand=False)\n",
    "    df['filename'] = filenames[0]\n",
    "    df.loc[df['type'] == 'transcriptome', 'Experiment_target'] = 'mRNA'\n",
    "    df = df.astype(str)\n",
    "    return df\n",
    "\n",
    "def read_sra_metadata(fpath):\n",
    "    df = pd.read_csv(fpath, sep='\\t')\n",
    "    select_cells = df['cell'].isin(['liver', 'kidney', 'ncd4', 'heart', 'blood'])\n",
    "    df = df.loc[select_cells, :].copy()\n",
    "    df.drop(['comment', 'use', 'date', 'runtype', 'readlength',\n",
    "             'SRA_ReadClass', 'platform', 'url', 'experiment'], axis=1, inplace=True)\n",
    "    df['project'] = 'SRA'\n",
    "    df.loc[df['GEO_Sample'] == 'na', ['GEO_Sample', 'GEO_Series']] = 'N/A'\n",
    "    df['type'] = 'transcriptome'\n",
    "    df['Experiment_target'] = 'mRNA'\n",
    "    df['url'] = 'empty'\n",
    "    new_cols = []\n",
    "    for c in df.columns:\n",
    "        if c == 'download_path':\n",
    "            new_cols.append('url')\n",
    "        elif c == 'cell':\n",
    "            new_cols.append('biosample')\n",
    "        else:\n",
    "            new_cols.append(c)\n",
    "    df.columns = new_cols\n",
    "    df = df.astype(str)\n",
    "    ena_url = 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/{run_short}/{run_full}/{read}'\n",
    "    for row in df.itertuples():\n",
    "        sraid = row.sraid\n",
    "        repid = row.rep\n",
    "        dl_url = ena_url.format(**{'run_short': sraid[:6],\n",
    "                                   'run_full': sraid,\n",
    "                                   'read': sraid + '_' + repid + '.fastq.gz'})\n",
    "        df.loc[row.Index, 'url'] = dl_url\n",
    "    df['Output_type'] = 'reads'\n",
    "    df['Biosample_type'] = 'tissue'\n",
    "    return df\n",
    " \n",
    "dset_lut = read_project_datasets(dataset_file)\n",
    "\n",
    "bp = read_blueprint_metadata(blueprint_file)\n",
    "deep = read_deep_metadata(deep_file)\n",
    "enc = read_encode_metadata(encode_file)\n",
    "sra = read_sra_metadata(sra_file)\n",
    "\n",
    "final = bp.merge(deep, how='outer')\n",
    "final = final.merge(enc, how='outer')\n",
    "final = final.merge(sra, how='outer')\n",
    "\n",
    "sids = []\n",
    "comm = []\n",
    "species = []\n",
    "spec_lut = {'hg19': 'human', 'mm9': 'mouse', 'rn5': 'rat', 'canFam3': 'dog',\n",
    "            'monDom5': 'opossum', 'galGal3': 'chicken', 'felCat5': 'cat',\n",
    "            'bosTau7': 'cow', 'susScr2': 'pig', 'oviAri3': 'sheep', 'rheMac2': 'rhesus',\n",
    "            'equCab2': 'horse', 'oryCun2': 'rabbit'}\n",
    "for row in final.itertuples():\n",
    "    lut_key = row.assembly, row.type, row.project, row.biosample, row.lab\n",
    "    spec = spec_lut[row.assembly]\n",
    "    sid, com = dset_lut[lut_key]\n",
    "    if sid in ['TD21', 'TD22', 'ED13', 'ED14']:\n",
    "        com = 'Raw-data-acces-{}'.format('https://www.ebi.ac.uk/ega/dacs/EGAC00001000179')\n",
    "    sids.append(sid)\n",
    "    comm.append(com)\n",
    "    species.append(spec)\n",
    "    \n",
    "final['short_id'] = sids\n",
    "final['comment'] = comm\n",
    "final['species'] = species\n",
    "\n",
    "final.fillna(value='N/A', inplace=True)\n",
    "final = final.astype(str)\n",
    "\n",
    "sort_cols = []\n",
    "for c in final.columns:\n",
    "    if c == 'short_id':\n",
    "        sort_cols.append((0, c))\n",
    "    elif c == 'assembly':\n",
    "        sort_cols.append((1, c))\n",
    "    elif c == 'type':\n",
    "        sort_cols.append((2, c))\n",
    "    elif c == 'project':\n",
    "        sort_cols.append((3, c))\n",
    "    elif c == 'biosample':\n",
    "        sort_cols.append((4, c))\n",
    "    elif c == 'lab':\n",
    "        sort_cols.append((5, c))\n",
    "    elif c == 'species':\n",
    "        sort_cols.append((6, c))\n",
    "    elif c == 'filename':\n",
    "        sort_cols.append((7, c))\n",
    "    elif c == 'comment':\n",
    "        sort_cols.append((1000, c))\n",
    "    else:\n",
    "        n = int((final[c] == 'N/A').sum() + 500)\n",
    "        sort_cols.append((n, c))\n",
    "        \n",
    "sort_cols = sorted(sort_cols)\n",
    "final = final[[c for n, c in sort_cols]]\n",
    "\n",
    "final['data_id'] = final['short_id'].str.extract('([0-9]+)', expand=False).astype(np.int16)\n",
    "final['data_type'] = final['short_id'].str.extract('(E|T){1}', expand=False)\n",
    "\n",
    "final.sort_values(['data_type', 'data_id', 'type', 'short_id', 'project', 'assembly'], inplace=True)\n",
    "\n",
    "final.drop(['data_id', 'data_type'], axis=1, inplace=True)\n",
    "\n",
    "final.to_csv(table_out, header=True, index=False,\n",
    "             columns=final.columns, sep='\\t')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
