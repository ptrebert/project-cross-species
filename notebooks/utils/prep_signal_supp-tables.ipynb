{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping data for reference  hg19\n",
      "Writing...\n",
      "Dumping data for reference  mm9\n",
      "Writing...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os as os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "project_base = '/TL/deep/fhgfs/projects/pebert/thesis/projects/cross_species/processing/norm'\n",
    "dir_testdata = os.path.join(project_base, 'task_testdata_exp/compfeat_groups')\n",
    "\n",
    "supplement = '/TL/deep-external01/nobackup/pebert/cloudshare/mpiinf/phd/chapter_projects/crossspecies/supplement/supp_tables'\n",
    "\n",
    "norm_samples = {'ESE14': 'esc', 'H1hESC': 'esc'}\n",
    "norm_region = {'reg5p': 'promoter', 'body': 'body'}\n",
    "\n",
    "extract_reg5p = ['name', 'symbol', 'start', 'end',\n",
    "                 'ftmsig_H3K27ac_abs_mean',\n",
    "                 'ftmsig_H3K4me3_abs_mean']\n",
    "\n",
    "extract_body = ['name', 'symbol', 'start', 'end',\n",
    "                'ftmsig_H3K36me3_abs_mean']\n",
    "\n",
    "select_cols = {'body': extract_body, 'promoter': extract_reg5p}\n",
    "\n",
    "def collect_testdata(root_path):\n",
    "    \n",
    "    subfolder = sorted(os.listdir(root_path), key=lambda x: x.split('_')[2])\n",
    "    target = None\n",
    "    trg_collect = []\n",
    "    for sub in subfolder:\n",
    "        qry, _, trg = sub.split('_')\n",
    "        if target is not None and trg != target:\n",
    "            print('Dumping data for reference ', target)\n",
    "            trg_collect = pd.concat(trg_collect, axis=0, ignore_index=False)\n",
    "            if pd.isnull(trg_collect).any(axis=1).any():\n",
    "                na_idx = pd.isnull(trg_collect).any(axis=1)\n",
    "                na_sub = trg_collect.loc[na_idx, :]\n",
    "                print(na_sub.head())\n",
    "                raise ValueError('Target merge produced NA')\n",
    "            if target == 'hg19':\n",
    "                prefix = 'Add-file-3_signal_'\n",
    "            else:\n",
    "                prefix = 'Add-file-4_signal_'\n",
    "            out_path = os.path.join(supplement, prefix + '{}-to-any.tsv.bz2'.format(target))\n",
    "            print('Writing...')\n",
    "            trg_collect.to_csv(out_path, sep='\\t', header=True, index=False,\n",
    "                               compression='bz2')\n",
    "            trg_collect = []            \n",
    "        target = trg\n",
    "        qry_collect = None\n",
    "        qry_done = set()\n",
    "        for ff in os.listdir(os.path.join(dir_testdata, sub)):\n",
    "            _, eid, qry, biosample = ff.split('.')[0].split('_')\n",
    "            biosample = norm_samples.get(biosample, biosample)\n",
    "            regtype = ff.split('.')[-2]\n",
    "            regtype = norm_region.get(regtype, regtype)\n",
    "            if regtype == 'uprr' or (eid, regtype) in qry_done:\n",
    "                continue\n",
    "            qry_done.add((eid, regtype))\n",
    "            fpath = os.path.join(dir_testdata, sub, ff)\n",
    "            col_subset = select_cols[regtype]\n",
    "            file_collect = []\n",
    "            with pd.HDFStore(fpath, 'r') as hdf:\n",
    "                for k in hdf.keys():\n",
    "                    if k.startswith('/metadata'):\n",
    "                        continue\n",
    "                    chrom = k.split('/')[-1]\n",
    "                    data = hdf[k].loc[:, col_subset]\n",
    "                    data['chrom'] = chrom\n",
    "                    data['assembly'] = qry\n",
    "                    new_cols = []\n",
    "                    for c in data.columns:\n",
    "                        if c.startswith('ftmsig'):\n",
    "                            new_col = c.replace('ftmsig', '{}_{}'.format(eid, biosample))\n",
    "                            new_col = new_col.replace('abs_mean', 'sig_{}'.format(regtype))\n",
    "                            new_cols.append(new_col)\n",
    "                        elif c in ['start', 'end']:\n",
    "                            new_col = c + '_{}'.format(regtype)\n",
    "                            new_cols.append(new_col)\n",
    "                        else:\n",
    "                            new_cols.append(c)\n",
    "                    data.columns = new_cols\n",
    "                    file_collect.append(data)\n",
    "            file_collect = pd.concat(file_collect, axis=0, ignore_index=False)\n",
    "            if pd.isnull(file_collect).any(axis=0).any():\n",
    "                print('File merge failed {}/{}'.format(sub, ff))\n",
    "                raise ValueError()\n",
    "            if qry_collect is None:\n",
    "                qry_collect = file_collect.copy()\n",
    "            else:\n",
    "                shared_keys = set(qry_collect.columns).intersection(set(file_collect.columns))\n",
    "                qry_collect = qry_collect.merge(file_collect, on=sorted(shared_keys), suffixes=('', ''))\n",
    "                if pd.isnull(qry_collect).any(axis=0).any():\n",
    "                    print('Query merge failed {}/{}'.format(sub, ff))\n",
    "                    raise ValueError()\n",
    "        trg_collect.append(qry_collect)\n",
    "    print('Dumping data for reference ', target)\n",
    "    trg_collect = pd.concat(trg_collect, axis=0, ignore_index=False)\n",
    "    if target == 'hg19':\n",
    "        prefix = 'Add-file-3_signal_'\n",
    "    else:\n",
    "        prefix = 'Add-file-4_signal_'\n",
    "    out_path = os.path.join(supplement, prefix + '{}-to-any.tsv.bz2'.format(target))\n",
    "    print('Writing...')\n",
    "    trg_collect.to_csv(out_path, sep='\\t', header=True, index=False,\n",
    "                       compression='bz2')\n",
    "    trg_collect = []\n",
    "    print('Done')\n",
    "    return\n",
    "             \n",
    "            \n",
    "collect_testdata(dir_testdata)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
