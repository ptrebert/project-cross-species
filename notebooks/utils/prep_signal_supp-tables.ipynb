{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping data for reference  hg19\n",
      "Writing...\n",
      "Dumping data for reference  mm9\n",
      "Writing...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os as os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "project_base = '/TL/deep/fhgfs/projects/pebert/thesis/projects/cross_species/processing/norm'\n",
    "dir_testdata = os.path.join(project_base, 'task_testdata_exp/compfeat_groups')\n",
    "\n",
    "supplement = '/TL/deep-external01/nobackup/pebert/cloudshare/mpiinf/phd/chapter_projects/crossspecies/supplement/supp_tables'\n",
    "\n",
    "norm_samples = {'ESE14': 'esc', 'H1hESC': 'esc'}\n",
    "norm_region = {'reg5p': 'promoter', 'body': 'body'}\n",
    "\n",
    "extract_reg5p = ['name', 'symbol', 'start', 'end',\n",
    "                 'ftmsig_H3K27ac_abs_mean',\n",
    "                 'ftmsig_H3K4me3_abs_mean']\n",
    "\n",
    "extract_body = ['name', 'symbol', 'start', 'end',\n",
    "                'ftmsig_H3K36me3_abs_mean']\n",
    "\n",
    "select_cols = {'body': extract_body, 'promoter': extract_reg5p}\n",
    "\n",
    "query_sort_order = {'hg19': {'rheMac2': 0, 'mm9': 1, 'oryCun2': 2, 'rn5': 3,\n",
    "                             'felCat5': 4, 'bosTau7': 5, 'susScr2': 6, 'canFam3': 7,\n",
    "                             'equCab2': 8, 'oviAri3': 9, 'monDom5': 10, 'galGal3': 11},\n",
    "                    'mm9': {'rn5': 0, 'oryCun2': 1, 'hg19': 2, 'rheMac2': 3,\n",
    "                            'bosTau7': 4, 'susScr2': 5, 'equCab2': 6, 'galGal3': 7}}\n",
    "\n",
    "\n",
    "def dump_transfer_signal(data_collector, ref_species):\n",
    "    \n",
    "    data_collector = pd.concat(data_collector, ignore_index=False,\n",
    "                               axis=0, sort=False)\n",
    "    data_collector.reset_index(drop=True, inplace=True)\n",
    "    if pd.isnull(data_collector).any(axis=1).any():\n",
    "        # for species combinations where there is no RNA\n",
    "        # test data available, no signal should have been\n",
    "        # transferred (apparently, some error in the pipeline\n",
    "        # code for hg19; for mm9, this is indeed the case)\n",
    "        data_collector.fillna('no_transcriptome_available', inplace=True)\n",
    "    col_order = ['assembly', 'name', 'symbol', 'chrom',\n",
    "                 'start_promoter', 'end_promoter', 'start_body', 'end_body']\n",
    "    for c in sorted(data_collector.columns):\n",
    "        if c not in col_order:\n",
    "            col_order.append(c)\n",
    "    data_collector = data_collector[col_order]\n",
    "    if ref_species == 'hg19':\n",
    "        prefix = 'Additional-file-3_signal_'\n",
    "    else:\n",
    "        prefix = 'Additional-file-4_signal_'\n",
    "    out_path = os.path.join(supplement, prefix + '{}-to-any.tsv'.format(ref_species))\n",
    "    print('Writing...')\n",
    "    data_collector.to_csv(out_path, sep='\\t',\n",
    "                          header=True, index=False)\n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "def collect_testdata(root_path):\n",
    "    \n",
    "    all_subfolders = sorted(os.listdir(root_path))\n",
    "    subfolder = []\n",
    "    for s in all_subfolders:\n",
    "        qry, _, trg = s.split('_')\n",
    "        subfolder.append((trg, query_sort_order[trg][qry], s))\n",
    "    subfolder = sorted(subfolder)\n",
    "        \n",
    "    target = None\n",
    "    trg_collect = []\n",
    "    for ref_spec, idx, sub in subfolder:\n",
    "        qry, _, trg = sub.split('_')\n",
    "        if target is not None and trg != target:\n",
    "            print('Dumping data for reference ', target)\n",
    "            trg_collect = dump_transfer_signal(trg_collect, target)\n",
    "        target = trg\n",
    "        qry_collect = None\n",
    "        qry_done = set()\n",
    "        for ff in os.listdir(os.path.join(dir_testdata, sub)):\n",
    "            _, eid, qry, biosample = ff.split('.')[0].split('_')\n",
    "            biosample = norm_samples.get(biosample, biosample)\n",
    "            if biosample == 'esc':\n",
    "                if not (trg in ['hg19', 'mm9'] and qry in ['hg19', 'mm9']):\n",
    "                    # this catches the erroneous ESC transfer for hg19\n",
    "                    continue\n",
    "            regtype = ff.split('.')[-2]\n",
    "            regtype = norm_region.get(regtype, regtype)\n",
    "            if regtype == 'uprr' or (eid, regtype) in qry_done:\n",
    "                continue\n",
    "            qry_done.add((eid, regtype))\n",
    "            fpath = os.path.join(dir_testdata, sub, ff)\n",
    "            col_subset = select_cols[regtype]\n",
    "            file_collect = []\n",
    "            with pd.HDFStore(fpath, 'r') as hdf:\n",
    "                for k in hdf.keys():\n",
    "                    if k.startswith('/metadata'):\n",
    "                        continue\n",
    "                    chrom = k.split('/')[-1]\n",
    "                    data = hdf[k].loc[:, col_subset]\n",
    "                    data['chrom'] = chrom\n",
    "                    data['assembly'] = qry\n",
    "                    new_cols = []\n",
    "                    for c in data.columns:\n",
    "                        if c.startswith('ftmsig'):\n",
    "                            new_col = c.replace('ftmsig', '{}_{}'.format(eid, biosample))\n",
    "                            new_col = new_col.replace('abs_mean', 'sig_{}'.format(regtype))\n",
    "                            new_cols.append(new_col)\n",
    "                        elif c in ['start', 'end']:\n",
    "                            new_col = c + '_{}'.format(regtype)\n",
    "                            new_cols.append(new_col)\n",
    "                        else:\n",
    "                            new_cols.append(c)\n",
    "                    data.columns = new_cols\n",
    "                    file_collect.append(data)\n",
    "            file_collect = pd.concat(file_collect, axis=0, ignore_index=False)\n",
    "            if pd.isnull(file_collect).any(axis=0).any():\n",
    "                print('File merge failed {}/{}'.format(sub, ff))\n",
    "                raise ValueError()\n",
    "            if qry_collect is None:\n",
    "                qry_collect = file_collect.copy()\n",
    "            else:\n",
    "                shared_keys = set(qry_collect.columns).intersection(set(file_collect.columns))\n",
    "                qry_collect = qry_collect.merge(file_collect, on=sorted(shared_keys), suffixes=('', ''))\n",
    "                if pd.isnull(qry_collect).any(axis=0).any():\n",
    "                    print('Query merge failed {}/{}'.format(sub, ff))\n",
    "                    raise ValueError()\n",
    "        trg_collect.append(qry_collect)\n",
    "    print('Dumping data for reference ', target)\n",
    "    trg_collect = dump_transfer_signal(trg_collect, target)\n",
    "    print('Done')\n",
    "    return\n",
    "             \n",
    "            \n",
    "collect_testdata(dir_testdata)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
