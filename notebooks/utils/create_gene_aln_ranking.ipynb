{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing to do\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os as os\n",
    "import collections as collect\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "project_root = '/TL/deep/fhgfs/projects/pebert/thesis/projects/cross_species/processing/norm'\n",
    "\n",
    "feat_folder = os.path.join(project_root, 'task_testdata_exp', 'compfeat_groups')\n",
    "\n",
    "out_folder = os.path.join(project_root, 'caching', 'aln_ranking')\n",
    "\n",
    "def load_aln_info(fpath, aln_select, aln_col):\n",
    "    dataset = []\n",
    "    with pd.HDFStore(fpath, 'r') as hdf:\n",
    "        for k in hdf.keys():\n",
    "            if k != '/metadata':\n",
    "                data = hdf[k]\n",
    "                data = data.loc[:, ['name', aln_select]]\n",
    "                data.columns = ['name', aln_col]\n",
    "                dataset.append(data)\n",
    "    dataset = pd.concat(dataset, ignore_index=False, axis=0)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def cache_aln_ranks():\n",
    "    cache_file = os.path.join(out_folder, '20180618_gene-aln_ranks.h5')\n",
    "    if os.path.isfile(cache_file):\n",
    "        print('Nothing to do')\n",
    "        return\n",
    "    done = set()\n",
    "    # 101 here since right=False\n",
    "    bins = np.array(list(range(0, 100, 5)) + [101], dtype=np.float16)\n",
    "    filemode = 'w'\n",
    "    for root, dirs, files in os.walk(feat_folder):\n",
    "        if files:\n",
    "            query, _, target = os.path.split(root)[-1].split('_')\n",
    "            if (target, query) not in done:\n",
    "                body_file = [f for f in files if '.body.' in f and f.endswith('.h5')][0]\n",
    "                body_data = load_aln_info(os.path.join(root, body_file),\n",
    "                                          'ftmsig_H3K36me3_pct_cons',\n",
    "                                          'body_cons')\n",
    "                prom_file = [f for f in files if '.reg5p.' in f and f.endswith('.h5')][0]\n",
    "                prom_data = load_aln_info(os.path.join(root, prom_file),\n",
    "                                          'ftmsig_H3K4me3_pct_cons',\n",
    "                                          'prom_cons')\n",
    "                dataset = body_data.merge(prom_data, on='name', how='outer')\n",
    "                dataset['aln_score'] = dataset['body_cons']\n",
    "                dataset['aln_rank'] = dataset['aln_score'].rank(pct=True, ascending=True)\n",
    "                dataset['aln_level'] = np.digitize(dataset['aln_score'].values, bins, right=False)\n",
    "                # we start counting at 0...\n",
    "                dataset['aln_level'] -= 1\n",
    "                \n",
    "                with pd.HDFStore(cache_file, filemode) as hdf:\n",
    "                    store_path = os.path.join(target, query, 'aln_ranks')\n",
    "                    hdf.put(store_path, dataset)\n",
    "                filemode = 'a'\n",
    "                done.add((target, query))\n",
    "    return\n",
    "                \n",
    "cache_aln_ranks()\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
