{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os as os\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "\n",
    "# Manually create dumps for hg19/mm9 alignments in dump folder\n",
    "dump_folder = '/TL/deep/fhgfs/projects/pebert/thesis/refdata/chainfiles/hdf_map/dump'\n",
    "\n",
    "# run commands:\n",
    "# creepiest.py -nod dump --input ../hg19_to_mm9.idx.h5 -ig default -o hg19_to_mm9.qry.aln.tsv.gz -mapref query\n",
    "# creepiest.py -nod dump --input ../hg19_to_mm9.idx.h5 -ig default -o hg19_to_mm9.trg.aln.tsv.gz -mapref target\n",
    "\n",
    "# creepiest.py -nod dump --input ../mm9_to_hg19.idx.h5 -ig default -o mm9_to_hg19.qry.aln.tsv.gz -mapref query\n",
    "# creepiest.py -nod dump --input ../mm9_to_hg19.idx.h5 -ig default -o mm9_to_hg19.trg.aln.tsv.gz -mapref target\n",
    "\n",
    "# Manually intersect gene ROIs with alignment blocks\n",
    "isect_folder = os.path.join(dump_folder, 'isect')\n",
    "\n",
    "# run commands - print also genes w/o overlap\n",
    "# bedtools intersect -wao -a hsa_hg19_gencode_v19.reg5p.bed.gz -b mm9_to_hg19.qry.aln.tsv.gz > hg19_from_mm9.ovl.reg5p.tsv\n",
    "# bedtools intersect -wao -a hsa_hg19_gencode_v19.body.bed.gz -b mm9_to_hg19.qry.aln.tsv.gz > hg19_from_mm9.ovl.body.tsv\n",
    "\n",
    "# bedtools intersect -wao -a mmu_mm9_gencode_vM1.body.bed.gz -b hg19_to_mm9.qry.aln.tsv.gz > mm9_from_hg19.ovl.body.tsv\n",
    "# bedtools intersect -wao -a mmu_mm9_gencode_vM1.reg5p.bed.gz -b hg19_to_mm9.qry.aln.tsv.gz > mm9_from_hg19.ovl.reg5p.tsv\n",
    "\n",
    "hsa_files = ['hg19_from_mm9.ovl.body.tsv', 'hg19_from_mm9.ovl.reg5p.tsv']\n",
    "mmu_files = ['mm9_from_hg19.ovl.body.tsv', 'mm9_from_hg19.ovl.reg5p.tsv']\n",
    "\n",
    "tsv_header = ['chrom', 'start', 'end', 'name', 'score', 'strand_char', 'symbol',\n",
    "              'aln_chrom', 'aln_start', 'aln_end', 'block_id', 'overlap']\n",
    "\n",
    "\n",
    "def _replace_strand(x):\n",
    "    if x == '-':\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def load_overlap_table(fpath, prefix):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with open(fpath, 'r') as table:\n",
    "        df = pd.read_csv(table, sep='\\t', header=None, names=tsv_header,\n",
    "                         usecols=['chrom', 'start', 'end', 'name', 'symbol', 'strand_char', 'overlap'],\n",
    "                         dtype={'chrom': str, 'start': np.int32, 'end': np.int32,\n",
    "                                'name': str, 'symbol': str, 'strand_char': str, 'overlap': np.int32})\n",
    "        df = df.loc[df['chrom'].str.match('chr[0-9]+'), :].copy()\n",
    "        df[prefix + '_start'] = df['start']\n",
    "        df[prefix + '_end'] = df['end']\n",
    "        df[prefix + '_overlap'] = df['overlap']\n",
    "        df['strand'] = df['strand_char'].map(_replace_strand)\n",
    "        df.drop(['start', 'end', 'overlap', 'strand_char'], inplace=True, axis=1)\n",
    "    ovl_sum = df.groupby(['chrom', prefix + '_start', prefix + '_end', 'strand', 'symbol', 'name']).sum()\n",
    "    # not sure if groupby is guaranteed to keep order of items, so do explicit merging\n",
    "    ovl_sum['name'] = ovl_sum.index.get_level_values('name')\n",
    "    ovl_sum.reset_index(drop=True, inplace=True)\n",
    "    df.drop([prefix + '_overlap'], axis=1, inplace=True)\n",
    "    df.drop_duplicates(subset=['name', 'symbol'], inplace=True)\n",
    "    df = df.merge(ovl_sum, on='name', how='outer')\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_overlap_frames(fp_left, prefix_left, fp_right, prefix_right):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    assert prefix_left == 'promoter', 'Wrong prefix: {}'.format(prefix_left)\n",
    "    left = load_overlap_table(fp_left, prefix_left)\n",
    "    right = load_overlap_table(fp_right, prefix_right)\n",
    "    \n",
    "    left_ovl = prefix_left + '_overlap'\n",
    "    right_ovl = prefix_right + '_overlap'\n",
    "    \n",
    "    left = left.merge(right, on=['name', 'symbol', 'strand', 'chrom'], how='outer')\n",
    "    \n",
    "    # mark different subsets of unaligned or weakly aligned genes\n",
    "    left['unaln_both'] = np.array((left[left_ovl] < 100) & (left[right_ovl] < 100), dtype=np.int8)\n",
    "    left['unaln_prom'] = np.array((left[left_ovl] < 100) & (left[right_ovl] >= 100), dtype=np.int8)\n",
    "    left['unaln_body'] = np.array((left[left_ovl] >= 100) & (left[right_ovl] < 100), dtype=np.int8)\n",
    "    \n",
    "    return left\n",
    "\n",
    "\n",
    "out_folder = '/TL/deep-external01/nobackup/pebert/cloudshare/mpiinf/phd/chapter_projects/crossspecies/supplement'\n",
    "\n",
    "for species, files in zip(['hsa', 'mmu'], [hsa_files, mmu_files]):\n",
    "    spec_ovl = merge_overlap_frames(os.path.join(isect_folder, files[0]), 'promoter',\n",
    "                                    os.path.join(isect_folder, files[1]), 'body')\n",
    "    \n",
    "    subset = spec_ovl.loc[spec_ovl['unaln_both'] > 0, :]\n",
    "    \n",
    "    out_path = os.path.join(out_folder, '201709_{}_unaln_genes'.format(species))\n",
    "    \n",
    "    name_out = out_path + '_names.txt'\n",
    "    with open(name_out, 'w') as dump:\n",
    "        subset.to_csv(dump, columns=['name'], index=False, header=False)\n",
    "        \n",
    "    symbol_out = out_path + '_symbols.txt'\n",
    "    with open(symbol_out, 'w') as dump:\n",
    "        subset.to_csv(dump, columns=['symbol'], index=False, header=False)\n",
    "        \n",
    "    both_out = out_path + '_names-symbols.tsv'\n",
    "    with open(both_out, 'w') as dump:\n",
    "        subset.to_csv(dump, columns=['name', 'symbol'], sep='\\t', index=False, header=False)\n",
    "    \n",
    "    prom_bed = out_path + '_promoters.bed'\n",
    "    with open(prom_bed, 'w') as dump:\n",
    "        subset.to_csv(dump, columns=['chrom', 'promoter_start', 'promoter_end',\n",
    "                                     'name', 'symbol', 'strand'], sep='\\t', index=False, header=False)\n",
    "    \n",
    "    store_out = out_path + '_store.h5'\n",
    "    if os.path.isfile(store_out):\n",
    "        mode = 'a'\n",
    "    else:\n",
    "        mode = 'w'\n",
    "    with pd.HDFStore(store_out, mode, complib='blosc', complevel=9) as hdf:\n",
    "        hdf.put(species, spec_ovl, format='table')\n",
    "\n",
    "print('Done')    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
