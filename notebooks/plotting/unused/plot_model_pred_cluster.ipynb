{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached data\n",
      "Prediction clustering created\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os as os\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import json as js\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hier\n",
    "import pickle as pck\n",
    "import collections as col\n",
    "import operator as op\n",
    "import functools as fnt\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from scipy.stats import mannwhitneyu as mwu\n",
    "import scipy as sci\n",
    "\n",
    "sns.set(style='white',\n",
    "        font_scale=1.25,\n",
    "        rc={'font.family': ['sans-serif'],\n",
    "            'font.sans-serif': ['DejaVu Sans']})\n",
    "\n",
    "fhgfs_base = '/TL/deep/fhgfs/projects/pebert/thesis'\n",
    "stat_folder = os.path.join(fhgfs_base, 'projects/cross_species/processing/norm/task_summarize')\n",
    "stat_file = os.path.join(stat_folder, 'agg_expstat_est.h5')\n",
    "ortho_folder = os.path.join(fhgfs_base, 'projects/cross_species/processing/norm/task_ortho_pred')\n",
    "ortho_pred = os.path.join(ortho_folder, 'orthopred_odb_v9.h5')\n",
    "\n",
    "cache_dir = '/home/pebert/.jupyter/cache'\n",
    "clean_cache = False\n",
    "\n",
    "conf_folder = '/home/pebert/work/code/mpggit/crossspecies/graphics'\n",
    "\n",
    "plot_labels = js.load(open(os.path.join(conf_folder, 'labels', 'cs_labels.json'), 'r'))\n",
    "plot_colors = js.load(open(os.path.join(conf_folder, 'colors', 'cs_colors.json'), 'r'))\n",
    "plot_shapes = js.load(open(os.path.join(conf_folder, 'shapes', 'cs_shapes.json'), 'r'))\n",
    "\n",
    "run_pred_cluster = True\n",
    "\n",
    "show_figures = True\n",
    "\n",
    "out_folder = '/TL/deep-external01/nobackup/pebert/cloudshare/mpiinf/phd/chapter_projects/crossspecies/figures/pub'\n",
    "\n",
    "# for dumping genesets, need promoter annotation\n",
    "DATA_FREEZE = '201709'\n",
    "dir_annotation = '/TL/deep/fhgfs/projects/pebert/thesis/refdata/genemodel/subsets/protein_coding/roi_hdf'\n",
    "\n",
    "gene_annot = {'human': os.path.join(dir_annotation, 'hsa_hg19_gencode_v19.reg5p.h5'),\n",
    "              'mouse': os.path.join(dir_annotation, 'mmu_mm9_gencode_vM1.reg5p.h5')}\n",
    "\n",
    "out_genesets = '/TL/deep-external01/nobackup/pebert/cloudshare/mpiinf/phd/chapter_projects/crossspecies/supplement'\n",
    "\n",
    "save_figures = False\n",
    "\n",
    "def exec_pred_cluster():\n",
    "    cache_data = os.path.join(cache_dir, 'plot_pred_cluster.h5')\n",
    "    fullmodel = 'can'\n",
    "    if not run_pred_cluster:\n",
    "        return False\n",
    "    if clean_cache and os.path.isfile(cache_data):\n",
    "        os.unlink(cache_data)\n",
    "    if os.path.isfile(cache_data):\n",
    "        print('Loading cached data')\n",
    "        model_perf = dict()\n",
    "        with pd.HDFStore(cache_data, 'r') as hdf:\n",
    "            for k in hdf.keys():\n",
    "                if k == '/switch_genes':\n",
    "                    switch_genes = set(hdf[k].values)\n",
    "                    continue\n",
    "                _, spec_a, spec_b, modeltype = k.split('/')\n",
    "                data = hdf[k]\n",
    "                model_perf[spec_a, spec_b] = {modeltype: data}\n",
    "    else:\n",
    "        model_perf = collect_ortho_perf(ortho_pred, fullmodel)\n",
    "        model_perf, switch_genes = collect_model_stat_perf(stat_file, model_perf, 'pos', fullmodel)\n",
    "        with pd.HDFStore(cache_data, 'w') as hdf:\n",
    "            for spec_pair in model_perf.keys():\n",
    "                collected = model_perf[spec_pair]\n",
    "                for modeltype, df in collected.items():\n",
    "                    path = os.path.join(spec_pair[0], spec_pair[1], modeltype)\n",
    "                    hdf.put(path, df, type='fixed')\n",
    "            hdf.put('switch_genes', pd.Series(sorted(switch_genes), dtype='object'))\n",
    "        print('Writing cache file predicted label clustering')\n",
    "    for (spec_a, spec_b), perf in model_perf.items():\n",
    "        if 'orth' in list(perf.keys())[0]:\n",
    "            load_key = 'data_orth_pair'\n",
    "            out_class = 'orthologs'\n",
    "        else:\n",
    "            load_key = 'data_crp_{}_wg'.format(fullmodel)\n",
    "            out_class = 'genes'\n",
    "        model_perf = perf[load_key]\n",
    "        genesets = extract_genesets(model_perf)\n",
    "        dump_genesets(genesets, out_genesets, load_gene_annotation(gene_annot[spec_b]),\n",
    "                      spec_b, out_class)        \n",
    "        if False:\n",
    "            model_perf = model_perf.loc[model_perf.index.isin(switch_genes), :]\n",
    "\n",
    "            dm = dist.pdist(model_perf.transpose(), metric='hamming')\n",
    "            link = hier.linkage(dm, method='average')\n",
    "            dend = hier.dendrogram(link, labels=model_perf.columns, leaf_rotation=90)\n",
    "                 \n",
    "        plot_title = 'Testing: gene status prediction - {} model on {}'.format(spec_a, spec_b)\n",
    "        if save_figures and False:\n",
    "            outpath = os.path.join(out_folder, 'main', 'fig_X_main_{}-to-{}_testperf_curve.svg'.format(spec_a, spec_b))\n",
    "            fig.savefig(outpath, bbox_extra_artists=exart, bbox_inches='tight')\n",
    "            outpath = outpath.replace('.svg', '.png')\n",
    "            fig.savefig(outpath, bbox_extra_artists=exart, bbox_inches='tight', dpi=300)\n",
    "    return True\n",
    "       \n",
    "\n",
    "def load_gene_annotation(fpath):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    subsets = []\n",
    "    with pd.HDFStore(fpath, 'r') as hdf:\n",
    "        for k in hdf.keys():\n",
    "            if 'metadata' in k:\n",
    "                continue\n",
    "            data = hdf[k]\n",
    "            _ , chrom = k.rsplit('/', 1)\n",
    "            data['chrom'] = chrom\n",
    "            subsets.append(data)\n",
    "    df = pd.concat(subsets, axis=0, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def dump_genesets(genesets, outfolder, annotation, species, out_class):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for sample, genes in genesets.items():\n",
    "        subset = annotation.loc[annotation['name'].isin(genes), :].copy()\n",
    "        outfile = '_'.join([DATA_FREEZE, species, sample, 'TP', out_class, 'promoters']) + '.bed'\n",
    "        outpath = os.path.join(outfolder, outfile)\n",
    "        subset.to_csv(outpath, sep='\\t', columns=['chrom', 'start', 'end', 'name', 'score', 'strand', 'symbol'],\n",
    "                      header=False, index=False)\n",
    "    return\n",
    "\n",
    "    \n",
    "def extract_genesets(model_perf):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    biosamples = col.defaultdict(dict)\n",
    "    # 'EE07_TE07-EE07_TE03_mm9_ESE14_true'\n",
    "    # 'EE07_TE07-EE07_TE03_mm9_ESE14_pred'\n",
    "    for c in model_perf.columns:\n",
    "        setting, sample, labels = c.rsplit('_', 2)\n",
    "        if setting not in biosamples[sample]:\n",
    "            biosamples[sample][setting] = {'true': '', 'pred': ''}\n",
    "        biosamples[sample][setting][labels] = c\n",
    "    genesets = col.defaultdict(set)\n",
    "    for smp, records in biosamples.items():\n",
    "        for setting, labels in records.items():\n",
    "            selector = np.logical_and(model_perf[labels['true']] > 0, model_perf[labels['pred']] > 0)\n",
    "            genes_on = model_perf.loc[selector, :].index.tolist()\n",
    "            if smp in genesets:\n",
    "                genesets[smp] = genesets[smp].intersection(genes_on)\n",
    "            else:\n",
    "                genesets[smp] = set(genes_on)\n",
    "    return genesets        \n",
    "    \n",
    "    \n",
    "def collect_model_stat_perf(fpath, data_collect, scenario, model_type):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    switching_genes = set()\n",
    "    with pd.HDFStore(fpath, 'r') as hdf:\n",
    "        load_keys = [k for k in hdf.keys() if k.startswith('/'.join(['', scenario, model_type])) and k.endswith('/data')]\n",
    "        for k in load_keys:\n",
    "            if any([c in k for c in ['GM12878', 'CH12', 'K562', 'MEL']]):\n",
    "                continue\n",
    "            # /pos/can/mouse/human/EE12_TS25_mm9_liver/EE12_TD21_hg19_hepa/data\n",
    "            _, _, _, spec_a, spec_b, data_a, data_b, _ = k.split('/')\n",
    "            if (spec_a, spec_b) not in [('human', 'mouse'), ('mouse', 'human')]:\n",
    "                continue\n",
    "            perf = hdf[k]\n",
    "            switching = set((perf.loc[perf['switching'] > 0, :]).index.tolist())\n",
    "            # switching genes are defined based on whole dataset, so this\n",
    "            # should always be the same set... if I am not mistaken...\n",
    "            if not switching_genes:\n",
    "                switching_genes = switching\n",
    "            else:\n",
    "                switching_genes = switching_genes.union(switching)\n",
    "            pair_prefix = data_a.rsplit('_', 2)[0]\n",
    "            label_true = '{}-{}_{}'.format(pair_prefix, data_b, 'true')\n",
    "            perf[label_true] = perf['true_class']\n",
    "            \n",
    "            label_pred = '{}-{}_{}'.format(pair_prefix, data_b, 'pred')\n",
    "            perf[label_pred] = perf['pred_class']\n",
    "            perf = perf[[label_true, label_pred]].copy()\n",
    "            model = 'data_crp_{}_wg'.format(model_type)\n",
    "            \n",
    "            if (spec_a, spec_b) not in data_collect:\n",
    "                data_collect[(spec_a, spec_b)] = {model: None}\n",
    "            \n",
    "            model_perf = data_collect[(spec_a, spec_b)][model]\n",
    "            if model_perf is None:\n",
    "                data_collect[(spec_a, spec_b)][model] = perf\n",
    "            else:\n",
    "                model_perf = pd.concat([model_perf, perf], ignore_index=False, axis=1)\n",
    "                data_collect[(spec_a, spec_b)][model] = model_perf            \n",
    "    return data_collect, switching_genes\n",
    "\n",
    "\n",
    "def collect_ortho_perf(fpath, model):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    collector = dict()\n",
    "    with pd.HDFStore(fpath, 'r') as hdf:\n",
    "        load_keys = [k for k in hdf.keys() if k.startswith('/pos/pair') and k.endswith('/data')]\n",
    "        for k in load_keys:\n",
    "            if any([c in k for c in ['GM12878', 'CH12', 'K562', 'MEL']]):\n",
    "                continue\n",
    "            # ['', 'pos', 'pair', 'mouse', 'human', 'TS31_mm9_ncd4', 'TD29_hg19_ncd4', 'data']\n",
    "            _, _, _, spec_a, spec_b, data_a, data_b, _ = k.split('/')\n",
    "            if (spec_a, spec_b) not in [('mouse', 'human'), ('human', 'mouse')]:\n",
    "                continue\n",
    "            perf = hdf[k]\n",
    "            pair_prefix = data_a.split('_')[0]\n",
    "            label_true = '{}-{}_{}'.format(pair_prefix, data_b, 'true')\n",
    "            perf[label_true] = np.array(perf[data_b] >= 1, dtype=np.int8)\n",
    "\n",
    "            label_pred = '{}-{}_{}'.format(pair_prefix, data_b, 'pred')\n",
    "            perf[label_pred] = np.array(perf[data_a] >= 1, dtype=np.int8)\n",
    "            perf.index = perf[spec_b + '_name']\n",
    "            perf = perf[[label_true, label_pred]].copy()\n",
    "            if (spec_a, spec_b) not in collector:\n",
    "                collector[(spec_a, spec_b)] = {'data_orth_pair': None,\n",
    "                                               'data_crp_{}_wg'.format(model): None}\n",
    "            \n",
    "            \n",
    "            orth_perf = collector[(spec_a, spec_b)]['data_orth_pair']\n",
    "            if orth_perf is None:\n",
    "                collector[(spec_a, spec_b)]['data_orth_pair'] = perf\n",
    "            else:\n",
    "                assert not any([c in orth_perf.columns for c in perf.columns]), 'Duplicate columns'\n",
    "                orth_perf = pd.concat([orth_perf, perf], ignore_index=False, axis=1)\n",
    "                collector[(spec_a, spec_b)]['data_orth_pair'] = orth_perf\n",
    "    return collector               \n",
    "                \n",
    "\n",
    "execd = exec_pred_cluster()\n",
    "if execd:\n",
    "    print('Prediction clustering created')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
