{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os as os\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import json as js\n",
    "import csv as csv\n",
    "import pickle as pck\n",
    "import collections as col\n",
    "import operator as op\n",
    "import functools as fnt\n",
    "import warnings as warn\n",
    "\n",
    "import sklearn.exceptions as skle\n",
    "\n",
    "warn.filterwarnings('error', message='Precision.+', category=skle.UndefinedMetricWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from scipy.stats import mannwhitneyu as mwu\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as pfm\n",
    "\n",
    "sns.set(style='white',\n",
    "        font_scale=1.25,\n",
    "        rc={'font.family': ['sans-serif'],\n",
    "            'font.sans-serif': ['DejaVu Sans']})\n",
    "\n",
    "fhgfs_base = '/TL/deep/fhgfs/projects/pebert/thesis'\n",
    "stat_folder = os.path.join(fhgfs_base, 'projects/cross_species/processing/norm/task_summarize')\n",
    "stat_file = os.path.join(stat_folder, 'agg_expstat_est.h5')\n",
    "ortho_folder = os.path.join(fhgfs_base, 'projects/cross_species/processing/norm/task_ortho_pred')\n",
    "ortho_pred = os.path.join(ortho_folder, 'orthopred_odb_v9.h5')\n",
    "\n",
    "cache_dir = '/home/pebert/.jupyter/cache'\n",
    "\n",
    "conf_folder = '/home/pebert/work/code/mpggit/crossspecies/graphics'\n",
    "ref_folder = '/home/pebert/work/code/mpggit/refdata/annotation'\n",
    "\n",
    "plot_labels = js.load(open(os.path.join(conf_folder, 'labels', 'cs_labels.json'), 'r'))\n",
    "plot_colors = js.load(open(os.path.join(conf_folder, 'colors', 'cs_colors.json'), 'r'))\n",
    "plot_shapes = js.load(open(os.path.join(conf_folder, 'shapes', 'cs_shapes.json'), 'r'))\n",
    "lca_times_file = os.path.join(ref_folder, 'lca_dist.tsv')\n",
    "species_file = os.path.join(ref_folder, 'species.tsv')\n",
    "\n",
    "run_exec_perf_comp = True\n",
    "\n",
    "show_figures = True\n",
    "\n",
    "out_folder = '/TL/deep-external01/nobackup/pebert/cloudshare/mpiinf/phd/chapter_projects/crossspecies/figures/pub'\n",
    "save_figures = True\n",
    "\n",
    "def exec_status():\n",
    "    cache_data = os.path.join(cache_dir, 'plot_perf_comp.h5')\n",
    "    fullmodel = 'can'\n",
    "    comparison = 'pos'\n",
    "    if os.path.isfile(cache_data):\n",
    "        perf_scores = dict()\n",
    "        with pd.HDFStore(cache_data, 'r') as hdf:\n",
    "            for k in hdf.keys():\n",
    "                lut_key = k.split('/')[1:]\n",
    "                perf_scores[tuple(lut_key)] = hdf[k]            \n",
    "    else:\n",
    "        perf_scores = collect_performances(stat_file, ortho_pred, fullmodel, comparison)\n",
    "        with pd.HDFStore(cache_data, 'w', complib='blosc', complevel=9) as hdf:\n",
    "            for key, value in perf_scores.items():\n",
    "                hdf.put('/'.join(key), value, format='table')\n",
    "\n",
    "    spec_pairs = sorted(set([(k[0], k[1]) for k in perf_scores.keys()]))\n",
    "    spec_plot = dict()\n",
    "    species_info, lca_dist = read_references(species_file, lca_times_file)\n",
    "    for trg, qry in spec_pairs:\n",
    "        total_genes = perf_scores[(trg, qry, 'total', 'model')]\n",
    "        total_ortho = perf_scores[(trg, qry, 'total', 'ortho')]\n",
    "        total_genes = total_genes.max(axis=0).max()\n",
    "        total_ortho = total_ortho.max(axis=0).max()\n",
    "        \n",
    "        sub_genes = perf_scores[(trg, qry, 'sub', 'model')]\n",
    "        sub_genes = sub_genes.median(axis=0)\n",
    "        \n",
    "        yl_model = perf_scores[(trg, qry, 'true', 'model')]\n",
    "        yl_model = yl_model.median(axis=0)\n",
    "        yl_ortho = perf_scores[(trg, qry, 'true', 'ortho')]\n",
    "        yl_ortho = yl_ortho.median(axis=0)\n",
    "        left_values = [yl_model, yl_ortho]\n",
    "        left_label = '# true predictions'\n",
    "        \n",
    "        yr_model = perf_scores[(trg, qry, 'f1', 'model')]\n",
    "        yr_model = yr_model.median(axis=0)\n",
    "        \n",
    "        if (trg, qry) in lca_dist and (trg, qry) not in spec_plot:\n",
    "            if trg in ['human', 'mouse']:\n",
    "                spec_plot[(trg, qry)] = {'dist': lca_dist[(trg, qry)],\n",
    "                                         'query': qry,\n",
    "                                         '50': float(yr_model['pred_prob_lo_50']),\n",
    "                                         '65': float(yr_model['pred_prob_lo_65']),\n",
    "                                         '80': float(yr_model['pred_prob_lo_80'])}\n",
    "        \n",
    "        yr_ortho = perf_scores[(trg, qry, 'f1', 'ortho')]\n",
    "        yr_ortho = yr_ortho.median(axis=0)\n",
    "        \n",
    "        right_values = [yr_model, yr_ortho]\n",
    "        right_label = 'F1 score'\n",
    "        \n",
    "        x_vals = np.array([int(c.split('_')[-1]) for c in yl_model.index], dtype=np.float16)\n",
    "        x_vals /= 100.\n",
    "        \n",
    "        spec_color = plot_colors['species'][qry]['rgb']\n",
    "        linecolors = [spec_color, 'darkgrey']\n",
    "        linestyles = ['solid', 'dashed']\n",
    "        linemarkers = ['^', 'v']\n",
    "        linelabels = ['ML model', 'Orthologs']\n",
    "         \n",
    "        plot_title = 'Gene status prediction from {} to {}'.format(trg, qry)\n",
    "        \n",
    "        if trg in ['human', 'mouse'] and qry in ['human', 'mouse']:\n",
    "            fig, exart = plot_perf_comp_lines(left_values, total_genes, right_values, x_vals, sub_genes,\n",
    "                                              left_label, right_label, plot_title,\n",
    "                                              linecolors, linestyles, linemarkers, linelabels)\n",
    "            if save_figures:\n",
    "                outpath = os.path.join(out_folder, 'main', 'fig_2B_main_{}-to-{}_testperf_curve.svg'.format(trg, qry))\n",
    "                fig.savefig(outpath, bbox_extra_artists=exart, bbox_inches='tight')\n",
    "                outpath = outpath.replace('.svg', '.png')\n",
    "                fig.savefig(outpath, bbox_extra_artists=exart, bbox_inches='tight', dpi=300)\n",
    "\n",
    "    hsa_comp = [v for k, v in spec_plot.items() if k[0] == 'human']\n",
    "    mmu_comp = [v for k, v in spec_plot.items() if k[0] == 'mouse']\n",
    "    fig, exart = plot_species_comp(hsa_comp, species_info, plot_colors, 'Gene status prediction human model')\n",
    "    if save_figures:\n",
    "        outpath = os.path.join(out_folder, 'main', 'fig_2C_main_human_testperf_all.svg')\n",
    "        fig.savefig(outpath, bbox_extra_artists=exart, bbox_inches='tight')\n",
    "        outpath = outpath.replace('.svg', '.png')\n",
    "        fig.savefig(outpath, bbox_extra_artists=exart, bbox_inches='tight', dpi=300)\n",
    "    fig, exart = plot_species_comp(mmu_comp, species_info, plot_colors, 'Gene status prediction mouse model')\n",
    "    if save_figures:\n",
    "        outpath = os.path.join(out_folder, 'main', 'fig_2C_main_mouse_testperf_all.svg')\n",
    "        fig.savefig(outpath, bbox_extra_artists=exart, bbox_inches='tight')\n",
    "        outpath = outpath.replace('.svg', '.png')\n",
    "        fig.savefig(outpath, bbox_extra_artists=exart, bbox_inches='tight', dpi=300)\n",
    "    return True\n",
    "   \n",
    "    \n",
    "def plot_perf_comp_lines(left_vals, left_max, right_vals, x_vals, sub_sizes,\n",
    "                         left_label, right_label, title,\n",
    "                         linecolors, linestyles, linemarkers, linelabels):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 8))\n",
    "    extra_artists = []\n",
    "    ax1.set_xlim(x_vals.min(), x_vals.max())\n",
    "    ax1.set_xlabel('Probability cut-off for predicted class', fontsize=14)\n",
    "    rounded_max = int(left_max // 1000 * 1000 + 1000)\n",
    "    yticks = list(range(0, rounded_max, 5000))\n",
    "    yticks.append(rounded_max)\n",
    "    ax1.set_yticks(yticks)\n",
    "    ax1.set_ylim(0, rounded_max)\n",
    "    ax1.set_ylabel(left_label, fontsize=14)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    \n",
    "    x_ticks_simple = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "    \n",
    "    ax1.set_xticks(x_ticks_simple)\n",
    "    ax1.set_xticklabels(list(map(str, x_ticks_simple)))\n",
    "    \n",
    "    handles = []\n",
    "    left_model = ax1.plot(x_vals, left_vals[0].values, linestyle=linestyles[0],\n",
    "                          color=linecolors[0], marker=linemarkers[0], markersize=10,\n",
    "                          zorder=3, label='Model true')\n",
    "    left_ortho = ax1.plot(x_vals, left_vals[1].values, linestyle=linestyles[0],\n",
    "                          color=linecolors[1], marker=linemarkers[1], markersize=10,\n",
    "                          zorder=2, label='Orth. true')\n",
    "    subset_size = ax1.plot(x_vals, sub_sizes.values, linestyle='dotted', color='darkgrey',\n",
    "                           marker=None, label='# genes', zorder=1)\n",
    "    handles.extend([left_model, left_ortho, subset_size])\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.set_ylabel(right_label, fontsize=14)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    \n",
    "    right_model = ax2.plot(x_vals, right_vals[0].values, linestyle=linestyles[1],\n",
    "                          color=linecolors[0], marker=linemarkers[0], markersize=10,\n",
    "                           zorder=3, label='Model F1')\n",
    "    right_ortho = ax2.plot(x_vals, right_vals[1].values, linestyle=linestyles[1],\n",
    "                           color=linecolors[1], marker=linemarkers[1], markersize=10,\n",
    "                           zorder=2, label='Orth. F1')\n",
    "    handles.extend([right_model, right_ortho])\n",
    "        \n",
    "    ax1_handles, ax1_labels = ax1.get_legend_handles_labels()\n",
    "    ax1_legend = ax1.legend(loc=3, fontsize=14)\n",
    "    \n",
    "    ax2_handles, ax2_labels = ax2.get_legend_handles_labels()\n",
    "    ax2_legend = ax2.legend(loc=4, fontsize=14)\n",
    "        \n",
    "    ax2.set_title(title, fontsize=16)\n",
    "    return fig, extra_artists\n",
    "\n",
    "\n",
    "def plot_species_comp(spec_data, spec_info, plot_colors, title):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(9, 7))\n",
    "    extra_artists = []\n",
    "    ax.set_xlim(0, len(spec_data))\n",
    "    x_vals = np.arange(0.5, len(spec_data), 1)\n",
    "    \n",
    "    ax.set_ylim(0.5, 1)\n",
    "    ax.set_ylabel('F1 score')\n",
    "    spec_data = sorted(spec_data, key=lambda d: d['dist'])\n",
    "        \n",
    "    for cutoff, style in zip(['50', '65', '80'], ['solid', 'dashed', 'dotted']):\n",
    "        y_vals = []\n",
    "        x_labels = []\n",
    "        last_lca = None\n",
    "        for x_val, record in zip(x_vals, spec_data):\n",
    "            spec_col = plot_colors['species'][record['query']]['rgb']\n",
    "            \n",
    "            ax.plot([x_val], [record[cutoff]], marker='o', markersize=8,\n",
    "                    color=spec_col, zorder=3)\n",
    "            \n",
    "            y_vals.append(record[cutoff])\n",
    "            x_labels.append(spec_info[record['query']]['common_name'])\n",
    "            if cutoff == '80':\n",
    "                if record['dist'] != last_lca:\n",
    "                    ax.text(x_val, 0.51, str(record['dist']), fontsize=14)\n",
    "                    last_lca = record['dist']\n",
    "        \n",
    "        ax.plot(x_vals, y_vals, color='grey', alpha=0.5, linestyle=style,\n",
    "                linewidth=2, label='Prob. > {}'.format(round(float(cutoff) / 100, 2)))\n",
    "    \n",
    "    ax.text(0.25, 0.55, 'LCA (mya):', fontsize=14)\n",
    "\n",
    "    ax.set_xticks(x_vals)\n",
    "    ax.set_xticklabels(x_labels, fontsize=14, rotation=30)\n",
    "        \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig_legend = ax.legend(loc=1, fontsize=14)\n",
    "        \n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    return fig, extra_artists\n",
    "\n",
    "\n",
    "def read_references(species, lca):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    lca_dist = dict()\n",
    "    with open(lca_times_file, 'r', newline='') as table:\n",
    "        rows = csv.DictReader(table, delimiter='\\t')\n",
    "        for r in rows:\n",
    "            if r['timetree-org'] in ['human', 'mouse']:\n",
    "                src = r['timetree-org']\n",
    "                for k, v in r.items():\n",
    "                    if k.startswith('time'):\n",
    "                        continue\n",
    "                    lca_dist[(src, k)] = int(v)\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    spec_ann = dict()\n",
    "    with open(species, 'r', newline='') as table:\n",
    "        rows = csv.DictReader(table, delimiter='\\t')\n",
    "        for r in rows:\n",
    "            spec_ann[r['common_name']] = r\n",
    "\n",
    "    return spec_ann, lca_dist\n",
    "\n",
    "\n",
    "def pair_model_ortholog_datasets(model_keys, ortho_keys):\n",
    "    \n",
    "    lut_okeys = dict()\n",
    "    for ok in ortho_keys:\n",
    "        parts = ok.split('/')\n",
    "        source, target = parts[5].split('_'), parts[6].split('_')\n",
    "        key = source[0], target[0]\n",
    "        if key in lut_okeys:\n",
    "            assert ok == lut_okeys[key], 'Dataset mismatch: {} / {}'.format(ok, lut_okeys[key])\n",
    "        lut_okeys[key] = ok, parts[5], parts[6]\n",
    "    \n",
    "    key_pairs = []\n",
    "    for mk in model_keys:\n",
    "        if any([c in mk for c in ['GM12878', 'CH12', 'K562', 'MEL']]):\n",
    "                continue\n",
    "        parts = mk.split('/')\n",
    "        source, target = parts[5].split('_'), parts[6].split('_')\n",
    "        key = source[1], target[1]\n",
    "        partner = lut_okeys[key]\n",
    "        key_pairs.append((parts[3], parts[4], mk, partner[0], partner[1], partner[2]))\n",
    "    return key_pairs\n",
    "    \n",
    "\n",
    "def compute_perf_scores(model_data, ortho_data, query_name, ortho_true, ortho_pred):\n",
    "    \n",
    "    lo_cols = sorted([c for c in model_data.columns if c.startswith('pred_prob_lo')],\n",
    "                     key=lambda x: int(x.split('_')[-1]))\n",
    "    assert query_name == model_data.index.name, 'Name mismatch: {} / {}'.format(query_name, mode_data.index.name)\n",
    "    assert query_name in ortho_data.columns, 'Undefined query name: {} / {}'.format(query_name, ortho_data.columns)\n",
    "    \n",
    "    perf_index = ['precision', 'recall', 'f1', 'true', 'sub', 'total']\n",
    "    \n",
    "    model_perf = pd.DataFrame(np.zeros((6, len(lo_cols)), dtype=np.float32), \n",
    "                              index=perf_index,\n",
    "                              columns=lo_cols)\n",
    "    ortho_perf = pd.DataFrame(np.zeros((6, len(lo_cols)), dtype=np.float32), \n",
    "                              index=perf_index,\n",
    "                              columns=lo_cols)\n",
    "    total_model = model_data.shape[0]\n",
    "    total_ortho = ortho_data.shape[0]\n",
    "    for c in lo_cols:\n",
    "        sub_model = model_data.loc[model_data[c] == 1, ['true_class', 'pred_class']]\n",
    "        if sub_model.empty:\n",
    "            model_perf[c] = pd.Series([0, 0, 0, 0, 0, total_model],\n",
    "                                      index=perf_index)\n",
    "            continue\n",
    "        try:\n",
    "            prec, rec, f1, _ = pfm(sub_model['true_class'], sub_model['pred_class'], average='micro')\n",
    "        except skle.UndefinedMetricWarning:\n",
    "            # this can happen if there are now predictions for one label\n",
    "            print('Model: UDM warning')\n",
    "            model_perf[c] = pd.Series([0, 0, 0, 0, 0, total_model],\n",
    "                                      index=perf_index)\n",
    "            continue\n",
    "        sub_size = sub_model.shape[0]\n",
    "        true_pred = (sub_model['true_class'] == sub_model['pred_class']).sum()\n",
    "        model_perf[c] = pd.Series([prec, rec, f1, true_pred, sub_size, total_model],\n",
    "                                  index=perf_index)\n",
    "        \n",
    "        sub_ortho = ortho_data.loc[ortho_data[query_name].isin(sub_model.index), :]\n",
    "        if sub_ortho.empty:\n",
    "            ortho_perf[c] = pd.Series([0, 0, 0, 0, 0, total_ortho],\n",
    "                                  index=perf_index)\n",
    "            continue\n",
    "        ortho_label_true = np.array(sub_ortho[ortho_true] >= 1, dtype=np.int8)\n",
    "        ortho_label_pred = np.array(sub_ortho[ortho_pred] >= 1, dtype=np.int8)\n",
    "        try:\n",
    "            prec, rec, f1, _ = pfm(ortho_label_true, ortho_label_pred, average='micro')\n",
    "        except skle.UndefinedMetricWarning:\n",
    "            print('Ortho: UDM warning')\n",
    "            ortho_perf[c] = pd.Series([0, 0, 0, 0, 0, total_ortho],\n",
    "                                  index=perf_index)\n",
    "            continue\n",
    "        sub_size = sub_ortho.shape[0]\n",
    "        true_pred = (ortho_label_true == ortho_label_pred).sum()\n",
    "        ortho_perf[c] = pd.Series([prec, rec, f1, true_pred, sub_size, total_ortho],\n",
    "                                  index=perf_index)\n",
    "    return model_perf, ortho_perf\n",
    "\n",
    "\n",
    "def collect_performances(model_file, ortho_file, model_type, comparison):\n",
    "    \n",
    "    with pd.HDFStore(model_file, 'r') as model_hdf:\n",
    "        filter_key = '/{}/{}'.format(comparison, model_type)\n",
    "        model_keys = [k for k in model_hdf.keys() if k.startswith(filter_key) and k.endswith('/data')]\n",
    "        with pd.HDFStore(ortho_file, 'r') as ortho_hdf:\n",
    "            filter_key = '/{}/pair'.format(comparison, 'pair')\n",
    "            ortho_keys = [k for k in ortho_hdf.keys() if k.startswith(filter_key) and k.endswith('/data')]\n",
    "            \n",
    "            key_pairs = pair_model_ortholog_datasets(model_keys, ortho_keys)\n",
    "            collect_scores = dict()\n",
    "            for trg, qry, model_key, ortho_key, ortho_pred, ortho_true in key_pairs:\n",
    "                model_data = model_hdf[model_key]\n",
    "                ortho_data = ortho_hdf[ortho_key]\n",
    "                model_perf, ortho_perf = compute_perf_scores(model_data, ortho_data,\n",
    "                                                             qry + '_name', ortho_true, ortho_pred)\n",
    "                for label in model_perf.index:\n",
    "                    if (trg, qry, label, 'model') in collect_scores:\n",
    "                        old = collect_scores[(trg, qry, label, 'model')]\n",
    "                        new = model_perf.loc[label, :].to_frame().transpose()\n",
    "                        new.index = [0]\n",
    "                        tmp = pd.concat([old, new], axis=0, ignore_index=True)\n",
    "                        collect_scores[(trg, qry, label, 'model')] = tmp\n",
    "                        \n",
    "                        old = collect_scores[(trg, qry, label, 'ortho')]\n",
    "                        new = ortho_perf.loc[label, :].to_frame().transpose()\n",
    "                        new.index = [0]\n",
    "                        tmp = pd.concat([old, new], axis=0, ignore_index=True)\n",
    "                        collect_scores[(trg, qry, label, 'ortho')] = tmp\n",
    "                    else:\n",
    "                        tmp = model_perf.loc[label, :].to_frame().transpose()\n",
    "                        tmp.index = [0]\n",
    "                        collect_scores[(trg, qry, label, 'model')] = tmp\n",
    "                        \n",
    "                        tmp = ortho_perf.loc[label, :].to_frame().transpose()\n",
    "                        tmp.index = [0]\n",
    "                        collect_scores[(trg, qry, label, 'ortho')] = tmp\n",
    "    return collect_scores\n",
    "\n",
    "\n",
    "if run_exec_perf_comp:\n",
    "    execd = exec_status()\n",
    "    print('Status plot created')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
