{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting model performance...\n",
      "Gene conservation cache exists\n",
      "15106\n",
      "10774\n",
      "0.713226532503641\n",
      "14124\n",
      "10194\n",
      "0.7217502124044181\n",
      "9770\n",
      "6907\n",
      "0.7069600818833163\n",
      "2670\n",
      "1735\n",
      "0.649812734082397\n",
      "572\n",
      "357\n",
      "0.6241258741258742\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-250b3c60f2b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_exec_perf_aln\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mexecd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexec_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Status plot created'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-250b3c60f2b4>\u001b[0m in \u001b[0;36mexec_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m         perf_scores = collect_performances(stat_file, stat_keys,\n\u001b[1;32m     87\u001b[0m                                            \u001b[0mgene_cons_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                                            fullmodel, comparison)\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blosc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-250b3c60f2b4>\u001b[0m in \u001b[0;36mcollect_performances\u001b[0;34m(model_file, model_keys, gene_cache, model_type, comparison)\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_preds\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msubset_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mcollect_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os as os\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import json as js\n",
    "import csv as csv\n",
    "import pickle as pck\n",
    "import collections as col\n",
    "import operator as op\n",
    "import functools as fnt\n",
    "import warnings as warn\n",
    "\n",
    "import sklearn.exceptions as skle\n",
    "\n",
    "warn.filterwarnings('error', message='Precision.+', category=skle.UndefinedMetricWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "# What is this?\n",
    "# Plot model performance for different\n",
    "# thresholds of (joint) promoter/gene body\n",
    "# conservation\n",
    "\n",
    "date = '20181121'\n",
    "\n",
    "sns.set(style='white',\n",
    "        font_scale=1.25,\n",
    "        rc={'font.family': ['sans-serif'],\n",
    "            'font.sans-serif': ['DejaVu Sans']})\n",
    "\n",
    "fhgfs_base = '/TL/deep/fhgfs/projects/pebert/thesis'\n",
    "stat_folder = os.path.join(fhgfs_base, 'projects/cross_species/processing/norm/task_summarize')\n",
    "stat_file = os.path.join(stat_folder, 'agg_expstat_est.h5')\n",
    "testdata_folder = os.path.join(fhgfs_base, 'projects/cross_species/processing/norm/task_testdata_exp/test_datasets')\n",
    "\n",
    "cache_dir = os.path.join(fhgfs_base, 'projects/cross_species/processing/norm/caching/notebooks')\n",
    "\n",
    "conf_folder = '/home/pebert/work/code/mpggit/crossspecies/graphics'\n",
    "ref_folder = '/home/pebert/work/code/mpggit/refdata/annotation'\n",
    "\n",
    "plot_labels = js.load(open(os.path.join(conf_folder, 'labels', 'cs_labels.json'), 'r'))\n",
    "plot_colors = js.load(open(os.path.join(conf_folder, 'colors', 'cs_colors.json'), 'r'))\n",
    "plot_shapes = js.load(open(os.path.join(conf_folder, 'shapes', 'cs_shapes.json'), 'r'))\n",
    "species_file = os.path.join(ref_folder, 'species.tsv')\n",
    "\n",
    "run_exec_perf_aln = True\n",
    "\n",
    "show_figures = False\n",
    "\n",
    "out_folder = '/TL/deep-external01/nobackup/pebert/cloudshare/mpiinf/phd/chapter_projects/crossspecies/figures/pub'\n",
    "diss_folder = '/home/pebert/work/code/mpggit/dissertation/Figures'\n",
    "save_figures = False\n",
    "save_diss = False\n",
    "\n",
    "def exec_status():\n",
    "    cache_data = os.path.join(cache_dir, '{}_plot_model_perf_aln.h5'.format(date))\n",
    "    cache_keys = os.path.join(cache_dir, '{}_plot_model_perf_aln.keys.pck')\n",
    "    if not os.path.isfile(cache_keys):\n",
    "        with pd.HDFStore(stat_file, 'r') as hdf:\n",
    "            stat_keys = list(hdf.keys())\n",
    "        with open(cache_keys, 'wb') as cache:\n",
    "            _ = pck.dump(stat_keys, cache)\n",
    "    else:\n",
    "        with open(cache_keys, 'rb') as cache:\n",
    "            stat_keys = pck.load(cache)\n",
    "        \n",
    "    fullmodel = 'can'\n",
    "    comparison = 'pos'\n",
    "    if os.path.isfile(cache_data):\n",
    "        perf_scores = dict()\n",
    "        with pd.HDFStore(cache_data, 'r') as hdf:\n",
    "            for k in hdf.keys():\n",
    "                pass\n",
    "                #lut_key = k.split('/')[1:]\n",
    "                #perf_scores[tuple(lut_key)] = hdf[k]            \n",
    "    else:\n",
    "        print('Collecting model performance...')\n",
    "        gene_cons_cache = os.path.join(cache_dir, '{}_gene_cons_cache.h5'.format(date))\n",
    "        _ = cache_gene_cons(gene_cons_cache)\n",
    "\n",
    "        perf_scores = collect_performances(stat_file, stat_keys,\n",
    "                                           gene_cons_cache,\n",
    "                                           fullmodel, comparison)\n",
    "        raise\n",
    "        with pd.HDFStore(cache_data, 'w', complib='blosc', complevel=9) as hdf:\n",
    "            for key, value in perf_scores.items():\n",
    "                hdf.put('/'.join(key), value, format='table')\n",
    "\n",
    "    spec_pairs = sorted(set([(k[0], k[1]) for k in perf_scores.keys()]))\n",
    "    fig_keys = {('human', 'mouse'): ('10', 'main'),\n",
    "                ('mouse', 'human'): ('S6', 'supp')}\n",
    "    for trg, qry in spec_pairs:\n",
    "        total_genes = perf_scores[(trg, qry, 'total', 'model')]\n",
    "        total_ortho = perf_scores[(trg, qry, 'total', 'ortho')]\n",
    "        total_genes = total_genes.max(axis=0).max()\n",
    "        total_ortho = total_ortho.max(axis=0).max()\n",
    "        \n",
    "        sub_genes = perf_scores[(trg, qry, 'sub', 'model')]\n",
    "        if sub_genes.shape[0] < 5:\n",
    "            select_pred = (sub_genes == 0).any(axis=0)\n",
    "            select_pred = ~select_pred\n",
    "        else:\n",
    "            select_pred = np.ones(sub_genes.shape[1]).astype(np.bool)\n",
    "        \n",
    "        sub_genes = sub_genes.median(axis=0)\n",
    "        sub_genes = sub_genes[select_pred]\n",
    "        \n",
    "        yl_model = perf_scores[(trg, qry, 'true', 'model')]\n",
    "        yl_model = yl_model.median(axis=0)\n",
    "        yl_model = yl_model[select_pred]\n",
    "        \n",
    "        yl_ortho = perf_scores[(trg, qry, 'true', 'ortho')]\n",
    "        yl_ortho = yl_ortho.median(axis=0)\n",
    "        yl_ortho = yl_ortho[select_pred]\n",
    "        \n",
    "        left_values = [yl_model, yl_ortho]\n",
    "        left_label = 'Number of true predictions'\n",
    "        \n",
    "        yr_model = perf_scores[(trg, qry, 'acc', 'model')]\n",
    "        yr_model = yr_model.median(axis=0)\n",
    "        yr_model = yr_model[select_pred]\n",
    "                \n",
    "        yr_ortho = perf_scores[(trg, qry, 'acc', 'ortho')]\n",
    "        yr_ortho = yr_ortho.median(axis=0)\n",
    "        yr_ortho = yr_ortho[select_pred]\n",
    "        \n",
    "        right_values = [yr_model, yr_ortho]\n",
    "        right_label = 'Accuracy (%)'\n",
    "        \n",
    "        x_vals = np.array([int(c.split('_')[-1]) for c in yl_model.index], dtype=np.float16)\n",
    "        x_vals /= 100.\n",
    "        \n",
    "        spec_color = plot_colors['species'][qry]['rgb']\n",
    "        # removed species color here\n",
    "        linecolors = ['dimgrey', 'darkgrey']\n",
    "        linestyles = ['solid', 'dashed']\n",
    "        linemarkers = ['^', 'v']\n",
    "        linelabels = ['Classifier', 'Orthologs']\n",
    "         \n",
    "        plot_title = '{}-to-{} model'.format(trg, qry)\n",
    "        \n",
    "        if trg in ['human', 'mouse'] and qry in ['human', 'mouse']:\n",
    "            fk, subfolder = fig_keys[(trg, qry)]\n",
    "            plot_title = fk\n",
    "            fig, exart = plot_perf_comp_lines(left_values, total_genes, right_values, x_vals, sub_genes,\n",
    "                                              left_label, right_label, plot_title,\n",
    "                                              linecolors, linestyles, linemarkers, linelabels,\n",
    "                                              save_diss)\n",
    "            if save_figures:\n",
    "                outname = 'fig_{}_{}-{}_testperf_prob'.format(fk, trg, qry)\n",
    "                \n",
    "                if save_diss:\n",
    "                    out_folder = diss_folder\n",
    "                    subfolder = 'crossspecies'\n",
    "                    \n",
    "                if not save_diss:\n",
    "                    outpath = os.path.join(out_folder, subfolder, 'raw', outname + '.svg')\n",
    "                    fig.savefig(outpath, bbox_extra_artists=exart, bbox_inches='tight')\n",
    "\n",
    "                    outpath = os.path.join(out_folder, subfolder, 'png', outname + '.png')\n",
    "                    fig.savefig(outpath, bbox_extra_artists=exart, bbox_inches='tight', dpi=300)\n",
    "                \n",
    "                outpath = os.path.join(out_folder, subfolder, outname + '.pdf')\n",
    "                fig.savefig(outpath, bbox_extra_artists=exart, bbox_inches='tight')\n",
    "                \n",
    "    return True\n",
    "   \n",
    "    \n",
    "def plot_perf_comp_lines(left_vals, left_max, right_vals, x_vals, sub_sizes,\n",
    "                         left_label, right_label, title,\n",
    "                         linecolors, linestyles, linemarkers, linelabels, save_diss=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 8))\n",
    "    extra_artists = []\n",
    "    ax1.set_xlim(x_vals.min() - 0.01, max(0.95, x_vals.max()) + 0.01)\n",
    "    ax1.set_xlabel('Probability cutoff for class predicted by classifier', fontsize=14)\n",
    "    rounded_max = int(left_max // 1000 * 1000 + 1000)\n",
    "    yticks = list(range(0, rounded_max, 5000))\n",
    "    yticks.append(rounded_max)\n",
    "    ax1.set_yticks(yticks)\n",
    "    ax1.set_ylim(0, rounded_max)\n",
    "    ax1.set_ylabel(left_label, fontsize=14)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    \n",
    "    x_ticks_simple = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "    \n",
    "    ax1.set_xticks(x_ticks_simple)\n",
    "    ax1.set_xticklabels(list(map(str, x_ticks_simple)))\n",
    "    \n",
    "    handles = []\n",
    "    left_model = ax1.plot(x_vals, left_vals[0].values, linestyle=linestyles[0],\n",
    "                          color=linecolors[0], marker=linemarkers[0], markersize=10,\n",
    "                          zorder=3, label='True classifier predictions')\n",
    "    left_ortho = ax1.plot(x_vals, left_vals[1].values, linestyle=linestyles[0],\n",
    "                          color=linecolors[1], marker=linemarkers[1], markersize=10,\n",
    "                          zorder=2, label='True ortholog predictions')\n",
    "    subset_size = ax1.plot(x_vals, sub_sizes.values, linestyle='dotted', color='darkgrey',\n",
    "                           marker=None, label='Selected genes', zorder=1)\n",
    "    handles.extend([left_model, left_ortho, subset_size])\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.set_yticks([0.25, 0.5, 0.75, 1.])\n",
    "    ax2.set_yticklabels(['25', '50', '75', '100'])\n",
    "    ax2.set_ylabel(right_label, fontsize=14)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    \n",
    "    right_model = ax2.plot(x_vals, right_vals[0].values, linestyle=linestyles[1],\n",
    "                          color=linecolors[0], marker=linemarkers[0], markersize=10,\n",
    "                           zorder=3, label='Classifier accuracy')\n",
    "    right_ortho = ax2.plot(x_vals, right_vals[1].values, linestyle=linestyles[1],\n",
    "                           color=linecolors[1], marker=linemarkers[1], markersize=10,\n",
    "                           zorder=2, label='Ortholog accuracy')\n",
    "    handles.extend([right_model, right_ortho])\n",
    "        \n",
    "    ax1_handles, ax1_labels = ax1.get_legend_handles_labels()\n",
    "    ax1_legend = ax1.legend(loc=3, fontsize=14)\n",
    "    \n",
    "    ax2_handles, ax2_labels = ax2.get_legend_handles_labels()\n",
    "    ax2_legend = ax2.legend(loc=4, fontsize=14)\n",
    "    \n",
    "    if not save_diss:\n",
    "        tt = ax2.set_title(title, fontsize=16)\n",
    "        tt.set_position([0.08, 1.01])\n",
    "    return fig, extra_artists\n",
    "\n",
    "\n",
    "def pair_model_ortholog_datasets(model_keys, ortho_keys):\n",
    "    \n",
    "    lut_okeys = dict()\n",
    "    for ok in ortho_keys:\n",
    "        parts = ok.split('/')\n",
    "        source, target = parts[5].split('_'), parts[6].split('_')\n",
    "        key = source[0], target[0]\n",
    "        if key in lut_okeys:\n",
    "            assert ok == lut_okeys[key], 'Dataset mismatch: {} / {}'.format(ok, lut_okeys[key])\n",
    "        lut_okeys[key] = ok, parts[5], parts[6]\n",
    "    \n",
    "    key_pairs = []\n",
    "    for mk in model_keys:\n",
    "        parts = mk.split('/')\n",
    "        source, target = parts[5].split('_'), parts[6].split('_')\n",
    "        key = source[1], target[1]\n",
    "        partner = lut_okeys[key]\n",
    "        key_pairs.append((parts[3], parts[4], mk, partner[0], partner[1], partner[2]))\n",
    "    return key_pairs\n",
    "    \n",
    "\n",
    "def cache_gene_cons(gene_cons_cache):\n",
    "    \n",
    "    if os.path.isfile(gene_cons_cache):\n",
    "        print('Gene conservation cache exists')\n",
    "        return gene_cons_cache\n",
    "    else:\n",
    "        with pd.HDFStore(gene_cons_cache, 'w') as hdf:\n",
    "            pass\n",
    "    \n",
    "    feat_columns = ['chrom', 'name', 'symbol',\n",
    "                    'start_body', 'end_body',\n",
    "                    'start_reg5p', 'end_reg5p',\n",
    "                    'ftlen_abs_length_reg5p',\n",
    "                    'ftmsig_H3K4me3_pct_cons_reg5p',\n",
    "                    'ftlen_abs_length_body',\n",
    "                    'ftmsig_H3K36me3_pct_cons_body']\n",
    "    \n",
    "    done = set()\n",
    "    for root, dirs, featfiles in os.walk(testdata_folder):\n",
    "        loadfiles = [ff for ff in featfiles if ff.startswith('G9930') and ff.endswith('.feat.h5')]\n",
    "        for ff in loadfiles:\n",
    "            fpath = os.path.join(root, ff)\n",
    "\n",
    "            trg, qry = None, None\n",
    "            cc = 0\n",
    "            data_buffer = []\n",
    "            with pd.HDFStore(fpath, 'r') as hdf:\n",
    "                for k in hdf.keys():\n",
    "                    if k.startswith('/metadata'):\n",
    "                        continue\n",
    "                    data = hdf[k]\n",
    "                    _, qry, _, trg, _, _, chrom = k.split('/')\n",
    "                    qry_spec = plot_colors['mapping'][qry]['species']\n",
    "                    trg_spec = plot_colors['mapping'][trg]['species']\n",
    "                    \n",
    "                    data['chrom'] = chrom\n",
    "                    data = data.loc[:, feat_columns].copy()\n",
    "\n",
    "                    data['promoter_cons_bp'] = (data['ftlen_abs_length_reg5p'] * \\\n",
    "                                                (data['ftmsig_H3K4me3_pct_cons_reg5p'] / 100.)).round(0).astype(np.int32)\n",
    "                    data['body_cons_bp'] = (data['ftlen_abs_length_body'] * \\\n",
    "                                           (data['ftmsig_H3K36me3_pct_cons_body'] / 100.)).round(0).astype(np.int32)\n",
    "                    data['pct_cons_locus'] = data['ftmsig_H3K4me3_pct_cons_reg5p'] + data['ftmsig_H3K36me3_pct_cons_body']\n",
    "                    data['pct_cons_locus'] /= 2.\n",
    "                    data['pct_cons_locus'] = data['pct_cons_locus'].round(2)\n",
    "\n",
    "                    data['unaln'] = ((data['body_cons_bp'] < 1) & (data['promoter_cons_bp'] < 1)).astype(np.int8)\n",
    "                    data['wkaln'] = ((data['body_cons_bp'] < 100) & (data['promoter_cons_bp'] < 100)).astype(np.int8)\n",
    "\n",
    "                    data['is_aligned'] = ((data['unaln'] < 1) & (data['wkaln'] < 1)).astype(np.int8)\n",
    "\n",
    "                    data_buffer.append(data)\n",
    "            data = pd.concat(data_buffer, axis=0, ignore_index=True)\n",
    "            if (trg, qry) in done:\n",
    "                raise ValueError('Duplicate entry for {} v {}'.format(trg, qry))\n",
    "            with pd.HDFStore(gene_cons_cache, 'a') as hdf:\n",
    "                hdf.put('{}/{}'.format(trg, qry), data, format='fixed')\n",
    "                hdf.put('{}/{}'.format(trg_spec, qry_spec), data, format='fixed')\n",
    "                \n",
    "    return gene_cons_cache\n",
    "\n",
    "\n",
    "def load_gene_cons_annotation(fpath, target, query):\n",
    "    \n",
    "    with pd.HDFStore(fpath, 'r') as hdf:\n",
    "        annotation = hdf['/'.join(['', target, query])]\n",
    "        annotation.index = annotation['name']\n",
    "    return annotation\n",
    "\n",
    "\n",
    "def collect_performances(model_file, model_keys, gene_cache, model_type, comparison):\n",
    "    \n",
    "    filter_key = '/{}/{}'.format(comparison, model_type)\n",
    "    load_keys = [k for k in model_keys if k.startswith(filter_key) and k.endswith('/data') and\n",
    "                 'G99' not in k]\n",
    "    with pd.HDFStore(model_file, 'r') as hdf:\n",
    "        \n",
    "        for lk in load_keys:\n",
    "            key_parts = lk.split('/')\n",
    "            trg, qry = key_parts[3:5]\n",
    "            \n",
    "            model_data = hdf[lk]\n",
    "            gene_data = load_gene_cons_annotation(gene_cache, trg, qry)\n",
    "            model_data = model_data.loc[model_data.index.isin(gene_data['name']), ['tp', 'tn']].copy()\n",
    "            model_data = model_data.join(gene_data, how='outer')\n",
    "            total_genes = model_data.shape[0]\n",
    "            model_data = model_data.loc[model_data['is_aligned'] > 0, ['tp', 'tn', 'pct_cons_locus']].copy()\n",
    "            aligned_genes = model_data.shape[0]\n",
    "            \n",
    "            for bound in zip([0, 25, 50, 75, 90]):\n",
    "                selector = np.array(model_data['pct_cons_locus'] > bound, dtype=np.bool)\n",
    "                subset = model_data.loc[selector, ['tp', 'tn']]\n",
    "                subset_size = subset.shape[0]\n",
    "                true_preds = subset['tn'].sum() + subset['tp'].sum()\n",
    "                print(subset_size)\n",
    "                print(true_preds)\n",
    "                print(true_preds / subset_size)\n",
    "            \n",
    "            raise\n",
    "        \n",
    "        collect_scores = dict()\n",
    "        for trg, qry, model_key, ortho_key, ortho_pred, ortho_true in key_pairs:\n",
    "            \n",
    "            ortho_data = ortho_hdf[ortho_key]\n",
    "            \n",
    "            for label in model_perf.index:\n",
    "                if (trg, qry, label, 'model') in collect_scores:\n",
    "                    old = collect_scores[(trg, qry, label, 'model')]\n",
    "                    new = model_perf.loc[label, :].to_frame().transpose()\n",
    "                    new.index = [0]\n",
    "                    tmp = pd.concat([old, new], axis=0, ignore_index=True)\n",
    "                    collect_scores[(trg, qry, label, 'model')] = tmp\n",
    "\n",
    "                    old = collect_scores[(trg, qry, label, 'ortho')]\n",
    "                    new = ortho_perf.loc[label, :].to_frame().transpose()\n",
    "                    new.index = [0]\n",
    "                    tmp = pd.concat([old, new], axis=0, ignore_index=True)\n",
    "                    collect_scores[(trg, qry, label, 'ortho')] = tmp\n",
    "                else:\n",
    "                    tmp = model_perf.loc[label, :].to_frame().transpose()\n",
    "                    tmp.index = [0]\n",
    "                    collect_scores[(trg, qry, label, 'model')] = tmp\n",
    "\n",
    "                    tmp = ortho_perf.loc[label, :].to_frame().transpose()\n",
    "                    tmp.index = [0]\n",
    "                    collect_scores[(trg, qry, label, 'ortho')] = tmp\n",
    "    return collect_scores\n",
    "\n",
    "\n",
    "if run_exec_perf_aln:\n",
    "    execd = exec_status()\n",
    "    print('Status plot created')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
